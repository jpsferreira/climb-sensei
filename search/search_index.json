{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"climb-sensei","text":"<p>A Python pose estimation tool for analyzing climbing footage. Extract vertical movement metrics, calculate biomechanics, visualize technique with animated dashboards, and analyze climbing performance using computer vision.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83c\udfaf Pose Detection: Real-time human pose estimation using MediaPipe with temporal smoothing</li> <li>\ud83d\udcca Performance Analysis: Comprehensive climbing metrics including speed, stability, smoothness, and body positioning</li> <li>\ud83c\udfaf Efficiency Metrics: Movement economy, lock-off detection, rest position identification, and fatigue scoring</li> <li>\ud83d\udcd0 Biomechanics: Calculate joint angles (8 joints), reach distances, and center of mass</li> <li>\ud83d\udcf9 Video Processing: Easy video I/O with pose overlay and animated metrics dashboards</li> <li>\ud83c\udfa8 Visualization: Draw pose landmarks, annotate metrics, and create real-time performance graphs</li> <li>\ud83d\udcc8 Temporal Analysis: Track metrics over time with jerk calculation, sway detection, and progression tracking</li> <li>\u2705 Well-Tested: 82% code coverage with 164 unit tests</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from climb_sensei import PoseEngine, VideoReader, ClimbingAnalyzer\n\n# Analyze climbing performance\nanalyzer = ClimbingAnalyzer(window_size=30, fps=30)\n\nwith PoseEngine() as engine:\n    with VideoReader('climbing_video.mp4') as video:\n        while True:\n            success, frame = video.read()\n            if not success:\n                break\n\n            # Detect pose and analyze\n            results = engine.process(frame)\n            if results:\n                landmarks = engine.extract_landmarks(results)\n                metrics = analyzer.analyze_frame(landmarks)\n\n                print(f\"Velocity: {metrics['com_velocity']:.4f}\")\n                print(f\"Stability: {metrics['com_sway']:.4f}\")\n\n# Get summary statistics\nsummary = analyzer.get_summary()\nprint(f\"Average speed: {summary['avg_velocity']:.4f}\")\nprint(f\"Total vertical progress: {summary['total_vertical_progress']:.3f}\")\n</code></pre>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>climb-sensei/\n\u251c\u2500\u2500 src/climb_sensei/\n\u2502   \u251c\u2500\u2500 __init__.py           # Package exports\n\u2502   \u251c\u2500\u2500 __main__.py           # Demo application\n\u2502   \u251c\u2500\u2500 config.py             # Configuration and constants\n\u2502   \u251c\u2500\u2500 video_io.py           # Video input/output handling\n\u2502   \u251c\u2500\u2500 pose_engine.py        # MediaPipe pose estimation\n\u2502   \u251c\u2500\u2500 biomechanics.py       # Pure mathematical calculations\n\u2502   \u251c\u2500\u2500 metrics.py            # ClimbingAnalyzer with temporal tracking\n\u2502   \u251c\u2500\u2500 metrics_viz.py        # Metrics dashboard visualization\n\u2502   \u2514\u2500\u2500 viz.py                # Pose visualization utilities\n\u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 analyze_climb.py      # Unified CLI (analysis + video generation)\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_*.py             # 164 comprehensive unit tests\n\u2502   \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 docs/                     # Documentation\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+ (tested on 3.12 and 3.13)</li> <li>mediapipe &gt;= 0.10.30</li> <li>opencv-python &gt;= 4.8.0</li> <li>numpy &gt;= 1.24.0</li> <li>tqdm &gt;= 4.66.0</li> </ul>"},{"location":"#license","title":"License","text":"<p>See LICENSE file for details.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please ensure:</p> <ul> <li>All functions have type hints</li> <li>Comprehensive docstrings</li> <li>Unit tests for new functionality</li> <li>Code follows existing style conventions</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for all public classes and functions.</p>"},{"location":"api/#climbinganalyzer","title":"ClimbingAnalyzer","text":"<p>Analyzes climbing performance through temporal pose tracking.</p> <p>Tracks body position over time to calculate movement metrics like stability, speed, vertical progression, efficiency, and technique quality.</p> <p>Active Metrics: - Hip height (vertical progression) - COM velocity (movement speed) - COM sway (stability) - Movement economy (efficiency) - Lock-off detection (static strength) - Rest position detection (recovery periods) - Fatigue indicators (quality degradation) - Joint angles (elbows, shoulders, knees, hips)</p> <p>Attributes:</p> Name Type Description <code>window_size</code> <p>Number of frames to use for temporal calculations</p> <code>fps</code> <p>Frames per second of video (for time-based metrics)</p> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>class ClimbingAnalyzer:\n    \"\"\"Analyzes climbing performance through temporal pose tracking.\n\n    Tracks body position over time to calculate movement metrics like\n    stability, speed, vertical progression, efficiency, and technique quality.\n\n    Active Metrics:\n    - Hip height (vertical progression)\n    - COM velocity (movement speed)\n    - COM sway (stability)\n    - Movement economy (efficiency)\n    - Lock-off detection (static strength)\n    - Rest position detection (recovery periods)\n    - Fatigue indicators (quality degradation)\n    - Joint angles (elbows, shoulders, knees, hips)\n\n    Attributes:\n        window_size: Number of frames to use for temporal calculations\n        fps: Frames per second of video (for time-based metrics)\n    \"\"\"\n\n    def __init__(self, window_size: int = 30, fps: float = 30.0):\n        \"\"\"Initialize the climbing analyzer.\n\n        Args:\n            window_size: Number of frames for temporal window (default: 30 frames = 1 sec @ 30fps)\n            fps: Frames per second for velocity calculations\n        \"\"\"\n        self.window_size = window_size\n        self.fps = fps\n        self.dt = 1.0 / fps  # Time between frames\n\n        # Temporal buffers for tracking\n        self._hip_heights: Deque[float] = deque(maxlen=window_size)\n        self._com_positions: Deque[tuple] = deque(maxlen=window_size)\n\n        # Full history for plotting (no max length)\n        self._history_hip_heights: List[float] = []\n        self._history_com_positions: List[tuple] = []\n        self._history_velocities: List[float] = []\n        self._history_sways: List[float] = []\n        self._history_jerks: List[float] = []\n        self._history_body_angles: List[float] = []\n        self._history_hand_spans: List[float] = []\n        self._history_foot_spans: List[float] = []\n        self._history_movement_economy: List[float] = []\n        self._history_lock_offs: List[bool] = []\n        self._history_rest_positions: List[bool] = []\n\n        # Joint angle tracking\n        self._history_joint_angles: Dict[str, List[float]] = {\n            \"left_elbow\": [],\n            \"right_elbow\": [],\n            \"left_shoulder\": [],\n            \"right_shoulder\": [],\n            \"left_knee\": [],\n            \"right_knee\": [],\n            \"left_hip\": [],\n            \"right_hip\": [],\n        }\n\n        # Summary statistics\n        self.total_frames = 0\n        self.initial_hip_height: Optional[float] = None\n        self._total_distance_traveled = 0.0\n\n    def analyze_frame(self, landmarks: List[Dict[str, float]]) -&gt; Dict[str, float]:\n        \"\"\"Analyze a single frame and return current metrics.\n\n        Args:\n            landmarks: List of landmark dictionaries with x, y, z coordinates\n\n        Returns:\n            Dictionary with current frame metrics:\n            - hip_height: Current hip height (normalized, 0-1)\n            - com_x, com_y: Center of mass position\n            - com_velocity: Speed of movement (units/second)\n            - com_sway: Lateral stability (std dev of x position)\n            - vertical_progress: Height gained from start (normalized)\n            - jerk: Movement smoothness\n            - body_angle: Lean angle from vertical\n            - hand_span: Distance between hands\n            - foot_span: Distance between feet\n            - movement_economy: Vertical progress / total distance (efficiency)\n            - is_lock_off: Boolean indicating lock-off position\n            - is_rest_position: Boolean indicating rest position\n            - left_elbow, right_elbow: Elbow angles\n            - left_shoulder, right_shoulder: Shoulder angles\n            - left_knee, right_knee: Knee angles\n            - left_hip, right_hip: Hip angles\n        \"\"\"\n        if len(landmarks) &lt; 33:\n            return {}\n\n        self.total_frames += 1\n\n        # Calculate hip height (average of left and right hip y-coordinates)\n        left_hip_y = landmarks[LandmarkIndex.LEFT_HIP][\"y\"]\n        right_hip_y = landmarks[LandmarkIndex.RIGHT_HIP][\"y\"]\n        hip_height = (left_hip_y + right_hip_y) / 2.0\n\n        # Store initial height for progress tracking\n        if self.initial_hip_height is None:\n            self.initial_hip_height = hip_height\n\n        # Calculate center of mass (using core body points)\n        core_points = [\n            (\n                landmarks[LandmarkIndex.LEFT_SHOULDER][\"x\"],\n                landmarks[LandmarkIndex.LEFT_SHOULDER][\"y\"],\n            ),\n            (\n                landmarks[LandmarkIndex.RIGHT_SHOULDER][\"x\"],\n                landmarks[LandmarkIndex.RIGHT_SHOULDER][\"y\"],\n            ),\n            (\n                landmarks[LandmarkIndex.LEFT_HIP][\"x\"],\n                landmarks[LandmarkIndex.LEFT_HIP][\"y\"],\n            ),\n            (\n                landmarks[LandmarkIndex.RIGHT_HIP][\"x\"],\n                landmarks[LandmarkIndex.RIGHT_HIP][\"y\"],\n            ),\n        ]\n        weights = np.ones(len(core_points))\n        com = calculate_center_of_mass(core_points, weights)\n\n        # Update temporal buffers\n        self._hip_heights.append(hip_height)\n        self._com_positions.append(com)\n\n        # Calculate metrics\n        metrics = {\n            \"hip_height\": hip_height,\n            \"com_x\": com[0],\n            \"com_y\": com[1],\n        }\n\n        # Velocity (requires at least 2 frames)\n        if len(self._com_positions) &gt;= 2:\n            prev_com = self._com_positions[-2]\n            curr_com = self._com_positions[-1]\n            dx = curr_com[0] - prev_com[0]\n            dy = curr_com[1] - prev_com[1]\n            distance = np.sqrt(dx**2 + dy**2)\n            velocity = distance / self.dt\n            metrics[\"com_velocity\"] = velocity\n        else:\n            velocity = 0.0\n            metrics[\"com_velocity\"] = 0.0\n\n        # Stability - lateral sway (std dev of x position over window)\n        if len(self._com_positions) &gt;= 3:\n            com_x_values = [pos[0] for pos in self._com_positions]\n            sway = float(np.std(com_x_values))\n            metrics[\"com_sway\"] = sway\n        else:\n            sway = 0.0\n            metrics[\"com_sway\"] = 0.0\n\n        # Vertical progress from start\n        metrics[\"vertical_progress\"] = self.initial_hip_height - hip_height\n\n        # Additional metrics\n        # Jerk (smoothness)\n        if len(self._com_positions) &gt;= 4:\n            jerk = AdvancedClimbingMetrics.calculate_jerk(\n                list(self._com_positions), self.dt\n            )\n            metrics[\"jerk\"] = jerk\n        else:\n            jerk = 0.0\n            metrics[\"jerk\"] = 0.0\n\n        # Body angle\n        body_angle = AdvancedClimbingMetrics.calculate_body_angle(landmarks)\n        metrics[\"body_angle\"] = body_angle\n\n        # Base of support\n        base_support = AdvancedClimbingMetrics.calculate_base_of_support(landmarks)\n        metrics[\"hand_span\"] = base_support.get(\"hand_span\", 0.0)\n        metrics[\"foot_span\"] = base_support.get(\"foot_span\", 0.0)\n        metrics[\"hand_foot_span\"] = base_support.get(\"hand_foot_span\", 0.0)\n\n        # Calculate joint angles\n        joint_angles = calculate_limb_angles(landmarks, LandmarkIndex)\n        metrics.update(joint_angles)\n\n        # Lock-off detection (elbow &lt; threshold AND low velocity)\n        left_lock_off = (\n            joint_angles.get(\"left_elbow\", 180)\n            &lt; MetricsConfig.LOCK_OFF_THRESHOLD_DEGREES\n            and velocity &lt; MetricsConfig.REST_VELOCITY_THRESHOLD\n        )\n        right_lock_off = (\n            joint_angles.get(\"right_elbow\", 180)\n            &lt; MetricsConfig.LOCK_OFF_THRESHOLD_DEGREES\n            and velocity &lt; MetricsConfig.REST_VELOCITY_THRESHOLD\n        )\n        is_lock_off = left_lock_off or right_lock_off\n        metrics[\"is_lock_off\"] = is_lock_off\n        metrics[\"left_lock_off\"] = left_lock_off\n        metrics[\"right_lock_off\"] = right_lock_off\n\n        # Rest position detection (low body angle AND low velocity)\n        # Body angle close to 0\u00b0 indicates vertical position\n        is_rest_position = (\n            body_angle &lt; MetricsConfig.REST_BODY_ANGLE_THRESHOLD\n            and velocity &lt; MetricsConfig.REST_VELOCITY_THRESHOLD\n        )\n        metrics[\"is_rest_position\"] = is_rest_position\n\n        # Movement economy (vertical progress / total distance traveled)\n        # Update total distance\n        if len(self._com_positions) &gt;= 2:\n            prev_pos = self._com_positions[-2]\n            curr_pos = self._com_positions[-1]\n            segment_distance = np.sqrt(\n                (curr_pos[0] - prev_pos[0]) ** 2 + (curr_pos[1] - prev_pos[1]) ** 2\n            )\n            self._total_distance_traveled += segment_distance\n\n        # Calculate economy ratio\n        if self._total_distance_traveled &gt; 0:\n            vertical_progress = self.initial_hip_height - hip_height\n            movement_economy = vertical_progress / self._total_distance_traveled\n        else:\n            movement_economy = 0.0\n        metrics[\"movement_economy\"] = movement_economy\n\n        # Store in history\n        self._history_hip_heights.append(hip_height)\n        self._history_com_positions.append(com)\n        self._history_velocities.append(velocity)\n        self._history_sways.append(sway)\n        self._history_jerks.append(jerk)\n        self._history_body_angles.append(body_angle)\n        self._history_hand_spans.append(metrics[\"hand_span\"])\n        self._history_foot_spans.append(metrics[\"foot_span\"])\n        self._history_movement_economy.append(movement_economy)\n        self._history_lock_offs.append(is_lock_off)\n        self._history_rest_positions.append(is_rest_position)\n\n        # Store joint angles\n        for joint_name in self._history_joint_angles:\n            angle_value = joint_angles.get(joint_name, 0.0)\n            self._history_joint_angles[joint_name].append(angle_value)\n\n        # Return dictionary for backward compatibility\n        # TODO: In next major version, return FrameMetrics directly\n        return metrics\n\n    def analyze_frame_typed(self, landmarks: List[Dict[str, float]]) -&gt; FrameMetrics:\n        \"\"\"Analyze frame and return typed metrics object.\n\n        This is the preferred method for type-safe code. Returns an immutable\n        FrameMetrics object instead of a dictionary.\n\n        Args:\n            landmarks: List of landmark dictionaries\n\n        Returns:\n            Immutable FrameMetrics object with type safety\n        \"\"\"\n        metrics_dict = self.analyze_frame(landmarks)\n        return FrameMetrics(\n            hip_height=metrics_dict[\"hip_height\"],\n            com_velocity=metrics_dict[\"com_velocity\"],\n            com_sway=metrics_dict[\"com_sway\"],\n            jerk=metrics_dict[\"jerk\"],\n            vertical_progress=metrics_dict[\"vertical_progress\"],\n            movement_economy=metrics_dict[\"movement_economy\"],\n            is_lock_off=metrics_dict[\"is_lock_off\"],\n            left_lock_off=metrics_dict[\"left_lock_off\"],\n            right_lock_off=metrics_dict[\"right_lock_off\"],\n            is_rest_position=metrics_dict[\"is_rest_position\"],\n            body_angle=metrics_dict[\"body_angle\"],\n            hand_span=metrics_dict[\"hand_span\"],\n            foot_span=metrics_dict[\"foot_span\"],\n            left_elbow=metrics_dict[\"left_elbow\"],\n            right_elbow=metrics_dict[\"right_elbow\"],\n            left_shoulder=metrics_dict[\"left_shoulder\"],\n            right_shoulder=metrics_dict[\"right_shoulder\"],\n            left_knee=metrics_dict[\"left_knee\"],\n            right_knee=metrics_dict[\"right_knee\"],\n            left_hip=metrics_dict[\"left_hip\"],\n            right_hip=metrics_dict[\"right_hip\"],\n        )\n\n    def get_summary(self) -&gt; Dict[str, float]:\n        \"\"\"Get summary statistics for the entire climb.\n\n        Returns:\n            Dictionary with summary metrics:\n            - total_frames: Number of frames analyzed\n            - avg_velocity: Average movement speed\n            - max_velocity: Maximum movement speed\n            - avg_sway: Average lateral instability\n            - avg_jerk: Average movement jerkiness\n            - avg_body_angle: Average lean angle\n            - avg_hand_span: Average distance between hands\n            - avg_foot_span: Average distance between feet\n            - total_vertical_progress: Total height gained\n            - max_height: Highest hip position reached\n            - min_height: Lowest hip position reached\n            - total_distance_traveled: Total COM movement distance\n            - avg_movement_economy: Average efficiency ratio\n            - lock_off_count: Number of frames in lock-off position\n            - lock_off_percentage: Percentage of time in lock-off\n            - rest_count: Number of frames in rest position\n            - rest_percentage: Percentage of time in rest\n            - fatigue_score: Quality degradation indicator (0-1, higher = more fatigued)\n            - avg_left_elbow, avg_right_elbow: Average elbow angles\n            - avg_left_shoulder, avg_right_shoulder: Average shoulder angles\n            - avg_left_knee, avg_right_knee: Average knee angles\n        \"\"\"\n        if self.total_frames == 0:\n            return {}\n\n        summary = {\n            \"total_frames\": self.total_frames,\n            \"avg_velocity\": (\n                float(np.mean(self._history_velocities))\n                if self._history_velocities\n                else 0.0\n            ),\n            \"max_velocity\": (\n                float(np.max(self._history_velocities))\n                if self._history_velocities\n                else 0.0\n            ),\n            \"avg_sway\": (\n                float(np.mean(self._history_sways)) if self._history_sways else 0.0\n            ),\n            \"max_sway\": (\n                float(np.max(self._history_sways)) if self._history_sways else 0.0\n            ),\n            \"avg_jerk\": (\n                float(np.mean(self._history_jerks)) if self._history_jerks else 0.0\n            ),\n            \"max_jerk\": (\n                float(np.max(self._history_jerks)) if self._history_jerks else 0.0\n            ),\n            \"avg_body_angle\": (\n                float(np.mean(self._history_body_angles))\n                if self._history_body_angles\n                else 0.0\n            ),\n            \"avg_hand_span\": (\n                float(np.mean(self._history_hand_spans))\n                if self._history_hand_spans\n                else 0.0\n            ),\n            \"avg_foot_span\": (\n                float(np.mean(self._history_foot_spans))\n                if self._history_foot_spans\n                else 0.0\n            ),\n            \"total_vertical_progress\": (\n                self.initial_hip_height - self._history_hip_heights[-1]\n                if self._history_hip_heights\n                else 0.0\n            ),\n            \"max_height\": (\n                self.initial_hip_height - min(self._history_hip_heights)\n                if self._history_hip_heights\n                else 0.0\n            ),\n            \"min_height\": (\n                self.initial_hip_height - max(self._history_hip_heights)\n                if self._history_hip_heights\n                else 0.0\n            ),\n            \"total_distance_traveled\": self._total_distance_traveled,\n            \"avg_movement_economy\": (\n                float(np.mean(self._history_movement_economy))\n                if self._history_movement_economy\n                else 0.0\n            ),\n            \"lock_off_count\": sum(self._history_lock_offs),\n            \"lock_off_percentage\": (\n                100.0 * sum(self._history_lock_offs) / len(self._history_lock_offs)\n                if self._history_lock_offs\n                else 0.0\n            ),\n            \"rest_count\": sum(self._history_rest_positions),\n            \"rest_percentage\": (\n                100.0\n                * sum(self._history_rest_positions)\n                / len(self._history_rest_positions)\n                if self._history_rest_positions\n                else 0.0\n            ),\n            \"fatigue_score\": self._calculate_fatigue_score(),\n        }\n\n        # Add average joint angles\n        for joint_name, angles in self._history_joint_angles.items():\n            if angles:\n                summary[f\"avg_{joint_name}\"] = float(np.mean(angles))\n\n        # Return dictionary for backward compatibility\n        # TODO: In next major version, return ClimbingSummary directly\n        return summary\n\n    def get_summary_typed(self) -&gt; ClimbingSummary:\n        \"\"\"Get typed summary statistics.\n\n        Returns immutable ClimbingSummary object for type-safe code.\n\n        Returns:\n            ClimbingSummary object with all statistics\n        \"\"\"\n        summary_dict = self.get_summary()\n        return ClimbingSummary(\n            total_frames=summary_dict[\"total_frames\"],\n            total_vertical_progress=summary_dict[\"total_vertical_progress\"],\n            max_height=summary_dict[\"max_height\"],\n            avg_velocity=summary_dict[\"avg_velocity\"],\n            max_velocity=summary_dict[\"max_velocity\"],\n            avg_sway=summary_dict[\"avg_sway\"],\n            max_sway=summary_dict[\"max_sway\"],\n            avg_jerk=summary_dict[\"avg_jerk\"],\n            max_jerk=summary_dict[\"max_jerk\"],\n            avg_body_angle=summary_dict[\"avg_body_angle\"],\n            avg_hand_span=summary_dict[\"avg_hand_span\"],\n            avg_foot_span=summary_dict[\"avg_foot_span\"],\n            total_distance_traveled=summary_dict[\"total_distance_traveled\"],\n            avg_movement_economy=summary_dict[\"avg_movement_economy\"],\n            lock_off_count=summary_dict[\"lock_off_count\"],\n            lock_off_percentage=summary_dict[\"lock_off_percentage\"],\n            rest_count=summary_dict[\"rest_count\"],\n            rest_percentage=summary_dict[\"rest_percentage\"],\n            fatigue_score=summary_dict[\"fatigue_score\"],\n            avg_left_elbow=summary_dict[\"avg_left_elbow\"],\n            avg_right_elbow=summary_dict[\"avg_right_elbow\"],\n            avg_left_shoulder=summary_dict[\"avg_left_shoulder\"],\n            avg_right_shoulder=summary_dict[\"avg_right_shoulder\"],\n            avg_left_knee=summary_dict[\"avg_left_knee\"],\n            avg_right_knee=summary_dict[\"avg_right_knee\"],\n            avg_left_hip=summary_dict[\"avg_left_hip\"],\n            avg_right_hip=summary_dict[\"avg_right_hip\"],\n        )\n\n    def _calculate_fatigue_score(self) -&gt; float:\n        \"\"\"Calculate fatigue score based on quality degradation.\n\n        Compares movement quality (jerk and sway) in first third vs last third.\n        Higher score = more fatigued (0.0 = no change, 1.0 = significant degradation)\n\n        Returns:\n            Fatigue score (0.0-1.0+)\n        \"\"\"\n        if len(self._history_jerks) &lt; MetricsConfig.FATIGUE_WINDOW_SIZE:\n            return 0.0\n\n        # Split into first third and last third\n        third = len(self._history_jerks) // 3\n        if third &lt; 10:  # Need enough data\n            return 0.0\n\n        early_jerks = self._history_jerks[:third]\n        late_jerks = self._history_jerks[-third:]\n\n        early_sways = self._history_sways[:third]\n        late_sways = self._history_sways[-third:]\n\n        # Calculate average values\n        early_jerk_avg = np.mean(early_jerks) if early_jerks else 0.0\n        late_jerk_avg = np.mean(late_jerks) if late_jerks else 0.0\n\n        early_sway_avg = np.mean(early_sways) if early_sways else 0.0\n        late_sway_avg = np.mean(late_sways) if late_sways else 0.0\n\n        # Calculate degradation (normalized to 0-1 range)\n        jerk_degradation = 0.0\n        if early_jerk_avg &gt; 0:\n            jerk_degradation = (late_jerk_avg - early_jerk_avg) / early_jerk_avg\n\n        sway_degradation = 0.0\n        if early_sway_avg &gt; 0:\n            sway_degradation = (late_sway_avg - early_sway_avg) / early_sway_avg\n\n        # Combined score (average of both indicators)\n        fatigue_score = max(0.0, (jerk_degradation + sway_degradation) / 2.0)\n\n        return float(fatigue_score)\n\n    def get_history(self) -&gt; Dict[str, List[float]]:\n        \"\"\"Get complete time-series history of all metrics.\n\n        Returns:\n            Dictionary with lists of metric values over time:\n            - hip_heights: Hip height at each frame\n            - velocities: Velocity at each frame\n            - sways: Lateral sway at each frame\n            - jerks: Jerk (smoothness) at each frame\n            - body_angles: Body angle at each frame\n            - hand_spans: Hand span at each frame\n            - foot_spans: Foot span at each frame\n            - movement_economy: Movement economy at each frame\n            - lock_offs: Lock-off detection at each frame (boolean)\n            - rest_positions: Rest position detection at each frame (boolean)\n            - joint_angles: Dictionary of joint angle histories\n        \"\"\"\n        history = {\n            \"hip_heights\": self._history_hip_heights.copy(),\n            \"velocities\": self._history_velocities.copy(),\n            \"sways\": self._history_sways.copy(),\n            \"jerks\": self._history_jerks.copy(),\n            \"body_angles\": self._history_body_angles.copy(),\n            \"hand_spans\": self._history_hand_spans.copy(),\n            \"foot_spans\": self._history_foot_spans.copy(),\n            \"movement_economy\": self._history_movement_economy.copy(),\n            \"lock_offs\": self._history_lock_offs.copy(),\n            \"rest_positions\": self._history_rest_positions.copy(),\n        }\n\n        # Add joint angle histories\n        for joint_name, angles in self._history_joint_angles.items():\n            history[joint_name] = angles.copy()\n\n        return history\n\n    def reset(self):\n        \"\"\"Reset the analyzer for a new climb.\"\"\"\n        self._hip_heights.clear()\n        self._com_positions.clear()\n        self._history_hip_heights.clear()\n        self._history_com_positions.clear()\n        self._history_velocities.clear()\n        self._history_sways.clear()\n        self._history_jerks.clear()\n        self._history_body_angles.clear()\n        self._history_hand_spans.clear()\n        self._history_foot_spans.clear()\n        self._history_movement_economy.clear()\n        self._history_lock_offs.clear()\n        self._history_rest_positions.clear()\n\n        # Reset joint angle histories\n        for joint_name in self._history_joint_angles:\n            self._history_joint_angles[joint_name].clear()\n\n        self.total_frames = 0\n        self.initial_hip_height = None\n        self._total_distance_traveled = 0.0\n</code></pre> <p>options: show_source: true heading_level: 3</p>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.__init__","title":"<code>__init__(window_size=30, fps=30.0)</code>","text":"<p>Initialize the climbing analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>Number of frames for temporal window (default: 30 frames = 1 sec @ 30fps)</p> <code>30</code> <code>fps</code> <code>float</code> <p>Frames per second for velocity calculations</p> <code>30.0</code> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def __init__(self, window_size: int = 30, fps: float = 30.0):\n    \"\"\"Initialize the climbing analyzer.\n\n    Args:\n        window_size: Number of frames for temporal window (default: 30 frames = 1 sec @ 30fps)\n        fps: Frames per second for velocity calculations\n    \"\"\"\n    self.window_size = window_size\n    self.fps = fps\n    self.dt = 1.0 / fps  # Time between frames\n\n    # Temporal buffers for tracking\n    self._hip_heights: Deque[float] = deque(maxlen=window_size)\n    self._com_positions: Deque[tuple] = deque(maxlen=window_size)\n\n    # Full history for plotting (no max length)\n    self._history_hip_heights: List[float] = []\n    self._history_com_positions: List[tuple] = []\n    self._history_velocities: List[float] = []\n    self._history_sways: List[float] = []\n    self._history_jerks: List[float] = []\n    self._history_body_angles: List[float] = []\n    self._history_hand_spans: List[float] = []\n    self._history_foot_spans: List[float] = []\n    self._history_movement_economy: List[float] = []\n    self._history_lock_offs: List[bool] = []\n    self._history_rest_positions: List[bool] = []\n\n    # Joint angle tracking\n    self._history_joint_angles: Dict[str, List[float]] = {\n        \"left_elbow\": [],\n        \"right_elbow\": [],\n        \"left_shoulder\": [],\n        \"right_shoulder\": [],\n        \"left_knee\": [],\n        \"right_knee\": [],\n        \"left_hip\": [],\n        \"right_hip\": [],\n    }\n\n    # Summary statistics\n    self.total_frames = 0\n    self.initial_hip_height: Optional[float] = None\n    self._total_distance_traveled = 0.0\n</code></pre>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.analyze_frame","title":"<code>analyze_frame(landmarks)</code>","text":"<p>Analyze a single frame and return current metrics.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[Dict[str, float]]</code> <p>List of landmark dictionaries with x, y, z coordinates</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary with current frame metrics:</p> <code>Dict[str, float]</code> <ul> <li>hip_height: Current hip height (normalized, 0-1)</li> </ul> <code>Dict[str, float]</code> <ul> <li>com_x, com_y: Center of mass position</li> </ul> <code>Dict[str, float]</code> <ul> <li>com_velocity: Speed of movement (units/second)</li> </ul> <code>Dict[str, float]</code> <ul> <li>com_sway: Lateral stability (std dev of x position)</li> </ul> <code>Dict[str, float]</code> <ul> <li>vertical_progress: Height gained from start (normalized)</li> </ul> <code>Dict[str, float]</code> <ul> <li>jerk: Movement smoothness</li> </ul> <code>Dict[str, float]</code> <ul> <li>body_angle: Lean angle from vertical</li> </ul> <code>Dict[str, float]</code> <ul> <li>hand_span: Distance between hands</li> </ul> <code>Dict[str, float]</code> <ul> <li>foot_span: Distance between feet</li> </ul> <code>Dict[str, float]</code> <ul> <li>movement_economy: Vertical progress / total distance (efficiency)</li> </ul> <code>Dict[str, float]</code> <ul> <li>is_lock_off: Boolean indicating lock-off position</li> </ul> <code>Dict[str, float]</code> <ul> <li>is_rest_position: Boolean indicating rest position</li> </ul> <code>Dict[str, float]</code> <ul> <li>left_elbow, right_elbow: Elbow angles</li> </ul> <code>Dict[str, float]</code> <ul> <li>left_shoulder, right_shoulder: Shoulder angles</li> </ul> <code>Dict[str, float]</code> <ul> <li>left_knee, right_knee: Knee angles</li> </ul> <code>Dict[str, float]</code> <ul> <li>left_hip, right_hip: Hip angles</li> </ul> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def analyze_frame(self, landmarks: List[Dict[str, float]]) -&gt; Dict[str, float]:\n    \"\"\"Analyze a single frame and return current metrics.\n\n    Args:\n        landmarks: List of landmark dictionaries with x, y, z coordinates\n\n    Returns:\n        Dictionary with current frame metrics:\n        - hip_height: Current hip height (normalized, 0-1)\n        - com_x, com_y: Center of mass position\n        - com_velocity: Speed of movement (units/second)\n        - com_sway: Lateral stability (std dev of x position)\n        - vertical_progress: Height gained from start (normalized)\n        - jerk: Movement smoothness\n        - body_angle: Lean angle from vertical\n        - hand_span: Distance between hands\n        - foot_span: Distance between feet\n        - movement_economy: Vertical progress / total distance (efficiency)\n        - is_lock_off: Boolean indicating lock-off position\n        - is_rest_position: Boolean indicating rest position\n        - left_elbow, right_elbow: Elbow angles\n        - left_shoulder, right_shoulder: Shoulder angles\n        - left_knee, right_knee: Knee angles\n        - left_hip, right_hip: Hip angles\n    \"\"\"\n    if len(landmarks) &lt; 33:\n        return {}\n\n    self.total_frames += 1\n\n    # Calculate hip height (average of left and right hip y-coordinates)\n    left_hip_y = landmarks[LandmarkIndex.LEFT_HIP][\"y\"]\n    right_hip_y = landmarks[LandmarkIndex.RIGHT_HIP][\"y\"]\n    hip_height = (left_hip_y + right_hip_y) / 2.0\n\n    # Store initial height for progress tracking\n    if self.initial_hip_height is None:\n        self.initial_hip_height = hip_height\n\n    # Calculate center of mass (using core body points)\n    core_points = [\n        (\n            landmarks[LandmarkIndex.LEFT_SHOULDER][\"x\"],\n            landmarks[LandmarkIndex.LEFT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[LandmarkIndex.RIGHT_SHOULDER][\"x\"],\n            landmarks[LandmarkIndex.RIGHT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[LandmarkIndex.LEFT_HIP][\"x\"],\n            landmarks[LandmarkIndex.LEFT_HIP][\"y\"],\n        ),\n        (\n            landmarks[LandmarkIndex.RIGHT_HIP][\"x\"],\n            landmarks[LandmarkIndex.RIGHT_HIP][\"y\"],\n        ),\n    ]\n    weights = np.ones(len(core_points))\n    com = calculate_center_of_mass(core_points, weights)\n\n    # Update temporal buffers\n    self._hip_heights.append(hip_height)\n    self._com_positions.append(com)\n\n    # Calculate metrics\n    metrics = {\n        \"hip_height\": hip_height,\n        \"com_x\": com[0],\n        \"com_y\": com[1],\n    }\n\n    # Velocity (requires at least 2 frames)\n    if len(self._com_positions) &gt;= 2:\n        prev_com = self._com_positions[-2]\n        curr_com = self._com_positions[-1]\n        dx = curr_com[0] - prev_com[0]\n        dy = curr_com[1] - prev_com[1]\n        distance = np.sqrt(dx**2 + dy**2)\n        velocity = distance / self.dt\n        metrics[\"com_velocity\"] = velocity\n    else:\n        velocity = 0.0\n        metrics[\"com_velocity\"] = 0.0\n\n    # Stability - lateral sway (std dev of x position over window)\n    if len(self._com_positions) &gt;= 3:\n        com_x_values = [pos[0] for pos in self._com_positions]\n        sway = float(np.std(com_x_values))\n        metrics[\"com_sway\"] = sway\n    else:\n        sway = 0.0\n        metrics[\"com_sway\"] = 0.0\n\n    # Vertical progress from start\n    metrics[\"vertical_progress\"] = self.initial_hip_height - hip_height\n\n    # Additional metrics\n    # Jerk (smoothness)\n    if len(self._com_positions) &gt;= 4:\n        jerk = AdvancedClimbingMetrics.calculate_jerk(\n            list(self._com_positions), self.dt\n        )\n        metrics[\"jerk\"] = jerk\n    else:\n        jerk = 0.0\n        metrics[\"jerk\"] = 0.0\n\n    # Body angle\n    body_angle = AdvancedClimbingMetrics.calculate_body_angle(landmarks)\n    metrics[\"body_angle\"] = body_angle\n\n    # Base of support\n    base_support = AdvancedClimbingMetrics.calculate_base_of_support(landmarks)\n    metrics[\"hand_span\"] = base_support.get(\"hand_span\", 0.0)\n    metrics[\"foot_span\"] = base_support.get(\"foot_span\", 0.0)\n    metrics[\"hand_foot_span\"] = base_support.get(\"hand_foot_span\", 0.0)\n\n    # Calculate joint angles\n    joint_angles = calculate_limb_angles(landmarks, LandmarkIndex)\n    metrics.update(joint_angles)\n\n    # Lock-off detection (elbow &lt; threshold AND low velocity)\n    left_lock_off = (\n        joint_angles.get(\"left_elbow\", 180)\n        &lt; MetricsConfig.LOCK_OFF_THRESHOLD_DEGREES\n        and velocity &lt; MetricsConfig.REST_VELOCITY_THRESHOLD\n    )\n    right_lock_off = (\n        joint_angles.get(\"right_elbow\", 180)\n        &lt; MetricsConfig.LOCK_OFF_THRESHOLD_DEGREES\n        and velocity &lt; MetricsConfig.REST_VELOCITY_THRESHOLD\n    )\n    is_lock_off = left_lock_off or right_lock_off\n    metrics[\"is_lock_off\"] = is_lock_off\n    metrics[\"left_lock_off\"] = left_lock_off\n    metrics[\"right_lock_off\"] = right_lock_off\n\n    # Rest position detection (low body angle AND low velocity)\n    # Body angle close to 0\u00b0 indicates vertical position\n    is_rest_position = (\n        body_angle &lt; MetricsConfig.REST_BODY_ANGLE_THRESHOLD\n        and velocity &lt; MetricsConfig.REST_VELOCITY_THRESHOLD\n    )\n    metrics[\"is_rest_position\"] = is_rest_position\n\n    # Movement economy (vertical progress / total distance traveled)\n    # Update total distance\n    if len(self._com_positions) &gt;= 2:\n        prev_pos = self._com_positions[-2]\n        curr_pos = self._com_positions[-1]\n        segment_distance = np.sqrt(\n            (curr_pos[0] - prev_pos[0]) ** 2 + (curr_pos[1] - prev_pos[1]) ** 2\n        )\n        self._total_distance_traveled += segment_distance\n\n    # Calculate economy ratio\n    if self._total_distance_traveled &gt; 0:\n        vertical_progress = self.initial_hip_height - hip_height\n        movement_economy = vertical_progress / self._total_distance_traveled\n    else:\n        movement_economy = 0.0\n    metrics[\"movement_economy\"] = movement_economy\n\n    # Store in history\n    self._history_hip_heights.append(hip_height)\n    self._history_com_positions.append(com)\n    self._history_velocities.append(velocity)\n    self._history_sways.append(sway)\n    self._history_jerks.append(jerk)\n    self._history_body_angles.append(body_angle)\n    self._history_hand_spans.append(metrics[\"hand_span\"])\n    self._history_foot_spans.append(metrics[\"foot_span\"])\n    self._history_movement_economy.append(movement_economy)\n    self._history_lock_offs.append(is_lock_off)\n    self._history_rest_positions.append(is_rest_position)\n\n    # Store joint angles\n    for joint_name in self._history_joint_angles:\n        angle_value = joint_angles.get(joint_name, 0.0)\n        self._history_joint_angles[joint_name].append(angle_value)\n\n    # Return dictionary for backward compatibility\n    # TODO: In next major version, return FrameMetrics directly\n    return metrics\n</code></pre>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.analyze_frame_typed","title":"<code>analyze_frame_typed(landmarks)</code>","text":"<p>Analyze frame and return typed metrics object.</p> <p>This is the preferred method for type-safe code. Returns an immutable FrameMetrics object instead of a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[Dict[str, float]]</code> <p>List of landmark dictionaries</p> required <p>Returns:</p> Type Description <code>FrameMetrics</code> <p>Immutable FrameMetrics object with type safety</p> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def analyze_frame_typed(self, landmarks: List[Dict[str, float]]) -&gt; FrameMetrics:\n    \"\"\"Analyze frame and return typed metrics object.\n\n    This is the preferred method for type-safe code. Returns an immutable\n    FrameMetrics object instead of a dictionary.\n\n    Args:\n        landmarks: List of landmark dictionaries\n\n    Returns:\n        Immutable FrameMetrics object with type safety\n    \"\"\"\n    metrics_dict = self.analyze_frame(landmarks)\n    return FrameMetrics(\n        hip_height=metrics_dict[\"hip_height\"],\n        com_velocity=metrics_dict[\"com_velocity\"],\n        com_sway=metrics_dict[\"com_sway\"],\n        jerk=metrics_dict[\"jerk\"],\n        vertical_progress=metrics_dict[\"vertical_progress\"],\n        movement_economy=metrics_dict[\"movement_economy\"],\n        is_lock_off=metrics_dict[\"is_lock_off\"],\n        left_lock_off=metrics_dict[\"left_lock_off\"],\n        right_lock_off=metrics_dict[\"right_lock_off\"],\n        is_rest_position=metrics_dict[\"is_rest_position\"],\n        body_angle=metrics_dict[\"body_angle\"],\n        hand_span=metrics_dict[\"hand_span\"],\n        foot_span=metrics_dict[\"foot_span\"],\n        left_elbow=metrics_dict[\"left_elbow\"],\n        right_elbow=metrics_dict[\"right_elbow\"],\n        left_shoulder=metrics_dict[\"left_shoulder\"],\n        right_shoulder=metrics_dict[\"right_shoulder\"],\n        left_knee=metrics_dict[\"left_knee\"],\n        right_knee=metrics_dict[\"right_knee\"],\n        left_hip=metrics_dict[\"left_hip\"],\n        right_hip=metrics_dict[\"right_hip\"],\n    )\n</code></pre>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.get_history","title":"<code>get_history()</code>","text":"<p>Get complete time-series history of all metrics.</p> <p>Returns:</p> Type Description <code>Dict[str, List[float]]</code> <p>Dictionary with lists of metric values over time:</p> <code>Dict[str, List[float]]</code> <ul> <li>hip_heights: Hip height at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>velocities: Velocity at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>sways: Lateral sway at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>jerks: Jerk (smoothness) at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>body_angles: Body angle at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>hand_spans: Hand span at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>foot_spans: Foot span at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>movement_economy: Movement economy at each frame</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>lock_offs: Lock-off detection at each frame (boolean)</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>rest_positions: Rest position detection at each frame (boolean)</li> </ul> <code>Dict[str, List[float]]</code> <ul> <li>joint_angles: Dictionary of joint angle histories</li> </ul> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def get_history(self) -&gt; Dict[str, List[float]]:\n    \"\"\"Get complete time-series history of all metrics.\n\n    Returns:\n        Dictionary with lists of metric values over time:\n        - hip_heights: Hip height at each frame\n        - velocities: Velocity at each frame\n        - sways: Lateral sway at each frame\n        - jerks: Jerk (smoothness) at each frame\n        - body_angles: Body angle at each frame\n        - hand_spans: Hand span at each frame\n        - foot_spans: Foot span at each frame\n        - movement_economy: Movement economy at each frame\n        - lock_offs: Lock-off detection at each frame (boolean)\n        - rest_positions: Rest position detection at each frame (boolean)\n        - joint_angles: Dictionary of joint angle histories\n    \"\"\"\n    history = {\n        \"hip_heights\": self._history_hip_heights.copy(),\n        \"velocities\": self._history_velocities.copy(),\n        \"sways\": self._history_sways.copy(),\n        \"jerks\": self._history_jerks.copy(),\n        \"body_angles\": self._history_body_angles.copy(),\n        \"hand_spans\": self._history_hand_spans.copy(),\n        \"foot_spans\": self._history_foot_spans.copy(),\n        \"movement_economy\": self._history_movement_economy.copy(),\n        \"lock_offs\": self._history_lock_offs.copy(),\n        \"rest_positions\": self._history_rest_positions.copy(),\n    }\n\n    # Add joint angle histories\n    for joint_name, angles in self._history_joint_angles.items():\n        history[joint_name] = angles.copy()\n\n    return history\n</code></pre>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.get_summary","title":"<code>get_summary()</code>","text":"<p>Get summary statistics for the entire climb.</p> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary with summary metrics:</p> <code>Dict[str, float]</code> <ul> <li>total_frames: Number of frames analyzed</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_velocity: Average movement speed</li> </ul> <code>Dict[str, float]</code> <ul> <li>max_velocity: Maximum movement speed</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_sway: Average lateral instability</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_jerk: Average movement jerkiness</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_body_angle: Average lean angle</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_hand_span: Average distance between hands</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_foot_span: Average distance between feet</li> </ul> <code>Dict[str, float]</code> <ul> <li>total_vertical_progress: Total height gained</li> </ul> <code>Dict[str, float]</code> <ul> <li>max_height: Highest hip position reached</li> </ul> <code>Dict[str, float]</code> <ul> <li>min_height: Lowest hip position reached</li> </ul> <code>Dict[str, float]</code> <ul> <li>total_distance_traveled: Total COM movement distance</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_movement_economy: Average efficiency ratio</li> </ul> <code>Dict[str, float]</code> <ul> <li>lock_off_count: Number of frames in lock-off position</li> </ul> <code>Dict[str, float]</code> <ul> <li>lock_off_percentage: Percentage of time in lock-off</li> </ul> <code>Dict[str, float]</code> <ul> <li>rest_count: Number of frames in rest position</li> </ul> <code>Dict[str, float]</code> <ul> <li>rest_percentage: Percentage of time in rest</li> </ul> <code>Dict[str, float]</code> <ul> <li>fatigue_score: Quality degradation indicator (0-1, higher = more fatigued)</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_left_elbow, avg_right_elbow: Average elbow angles</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_left_shoulder, avg_right_shoulder: Average shoulder angles</li> </ul> <code>Dict[str, float]</code> <ul> <li>avg_left_knee, avg_right_knee: Average knee angles</li> </ul> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def get_summary(self) -&gt; Dict[str, float]:\n    \"\"\"Get summary statistics for the entire climb.\n\n    Returns:\n        Dictionary with summary metrics:\n        - total_frames: Number of frames analyzed\n        - avg_velocity: Average movement speed\n        - max_velocity: Maximum movement speed\n        - avg_sway: Average lateral instability\n        - avg_jerk: Average movement jerkiness\n        - avg_body_angle: Average lean angle\n        - avg_hand_span: Average distance between hands\n        - avg_foot_span: Average distance between feet\n        - total_vertical_progress: Total height gained\n        - max_height: Highest hip position reached\n        - min_height: Lowest hip position reached\n        - total_distance_traveled: Total COM movement distance\n        - avg_movement_economy: Average efficiency ratio\n        - lock_off_count: Number of frames in lock-off position\n        - lock_off_percentage: Percentage of time in lock-off\n        - rest_count: Number of frames in rest position\n        - rest_percentage: Percentage of time in rest\n        - fatigue_score: Quality degradation indicator (0-1, higher = more fatigued)\n        - avg_left_elbow, avg_right_elbow: Average elbow angles\n        - avg_left_shoulder, avg_right_shoulder: Average shoulder angles\n        - avg_left_knee, avg_right_knee: Average knee angles\n    \"\"\"\n    if self.total_frames == 0:\n        return {}\n\n    summary = {\n        \"total_frames\": self.total_frames,\n        \"avg_velocity\": (\n            float(np.mean(self._history_velocities))\n            if self._history_velocities\n            else 0.0\n        ),\n        \"max_velocity\": (\n            float(np.max(self._history_velocities))\n            if self._history_velocities\n            else 0.0\n        ),\n        \"avg_sway\": (\n            float(np.mean(self._history_sways)) if self._history_sways else 0.0\n        ),\n        \"max_sway\": (\n            float(np.max(self._history_sways)) if self._history_sways else 0.0\n        ),\n        \"avg_jerk\": (\n            float(np.mean(self._history_jerks)) if self._history_jerks else 0.0\n        ),\n        \"max_jerk\": (\n            float(np.max(self._history_jerks)) if self._history_jerks else 0.0\n        ),\n        \"avg_body_angle\": (\n            float(np.mean(self._history_body_angles))\n            if self._history_body_angles\n            else 0.0\n        ),\n        \"avg_hand_span\": (\n            float(np.mean(self._history_hand_spans))\n            if self._history_hand_spans\n            else 0.0\n        ),\n        \"avg_foot_span\": (\n            float(np.mean(self._history_foot_spans))\n            if self._history_foot_spans\n            else 0.0\n        ),\n        \"total_vertical_progress\": (\n            self.initial_hip_height - self._history_hip_heights[-1]\n            if self._history_hip_heights\n            else 0.0\n        ),\n        \"max_height\": (\n            self.initial_hip_height - min(self._history_hip_heights)\n            if self._history_hip_heights\n            else 0.0\n        ),\n        \"min_height\": (\n            self.initial_hip_height - max(self._history_hip_heights)\n            if self._history_hip_heights\n            else 0.0\n        ),\n        \"total_distance_traveled\": self._total_distance_traveled,\n        \"avg_movement_economy\": (\n            float(np.mean(self._history_movement_economy))\n            if self._history_movement_economy\n            else 0.0\n        ),\n        \"lock_off_count\": sum(self._history_lock_offs),\n        \"lock_off_percentage\": (\n            100.0 * sum(self._history_lock_offs) / len(self._history_lock_offs)\n            if self._history_lock_offs\n            else 0.0\n        ),\n        \"rest_count\": sum(self._history_rest_positions),\n        \"rest_percentage\": (\n            100.0\n            * sum(self._history_rest_positions)\n            / len(self._history_rest_positions)\n            if self._history_rest_positions\n            else 0.0\n        ),\n        \"fatigue_score\": self._calculate_fatigue_score(),\n    }\n\n    # Add average joint angles\n    for joint_name, angles in self._history_joint_angles.items():\n        if angles:\n            summary[f\"avg_{joint_name}\"] = float(np.mean(angles))\n\n    # Return dictionary for backward compatibility\n    # TODO: In next major version, return ClimbingSummary directly\n    return summary\n</code></pre>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.get_summary_typed","title":"<code>get_summary_typed()</code>","text":"<p>Get typed summary statistics.</p> <p>Returns immutable ClimbingSummary object for type-safe code.</p> <p>Returns:</p> Type Description <code>ClimbingSummary</code> <p>ClimbingSummary object with all statistics</p> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def get_summary_typed(self) -&gt; ClimbingSummary:\n    \"\"\"Get typed summary statistics.\n\n    Returns immutable ClimbingSummary object for type-safe code.\n\n    Returns:\n        ClimbingSummary object with all statistics\n    \"\"\"\n    summary_dict = self.get_summary()\n    return ClimbingSummary(\n        total_frames=summary_dict[\"total_frames\"],\n        total_vertical_progress=summary_dict[\"total_vertical_progress\"],\n        max_height=summary_dict[\"max_height\"],\n        avg_velocity=summary_dict[\"avg_velocity\"],\n        max_velocity=summary_dict[\"max_velocity\"],\n        avg_sway=summary_dict[\"avg_sway\"],\n        max_sway=summary_dict[\"max_sway\"],\n        avg_jerk=summary_dict[\"avg_jerk\"],\n        max_jerk=summary_dict[\"max_jerk\"],\n        avg_body_angle=summary_dict[\"avg_body_angle\"],\n        avg_hand_span=summary_dict[\"avg_hand_span\"],\n        avg_foot_span=summary_dict[\"avg_foot_span\"],\n        total_distance_traveled=summary_dict[\"total_distance_traveled\"],\n        avg_movement_economy=summary_dict[\"avg_movement_economy\"],\n        lock_off_count=summary_dict[\"lock_off_count\"],\n        lock_off_percentage=summary_dict[\"lock_off_percentage\"],\n        rest_count=summary_dict[\"rest_count\"],\n        rest_percentage=summary_dict[\"rest_percentage\"],\n        fatigue_score=summary_dict[\"fatigue_score\"],\n        avg_left_elbow=summary_dict[\"avg_left_elbow\"],\n        avg_right_elbow=summary_dict[\"avg_right_elbow\"],\n        avg_left_shoulder=summary_dict[\"avg_left_shoulder\"],\n        avg_right_shoulder=summary_dict[\"avg_right_shoulder\"],\n        avg_left_knee=summary_dict[\"avg_left_knee\"],\n        avg_right_knee=summary_dict[\"avg_right_knee\"],\n        avg_left_hip=summary_dict[\"avg_left_hip\"],\n        avg_right_hip=summary_dict[\"avg_right_hip\"],\n    )\n</code></pre>"},{"location":"api/#climb_sensei.metrics.ClimbingAnalyzer.reset","title":"<code>reset()</code>","text":"<p>Reset the analyzer for a new climb.</p> Source code in <code>src/climb_sensei/metrics.py</code> <pre><code>def reset(self):\n    \"\"\"Reset the analyzer for a new climb.\"\"\"\n    self._hip_heights.clear()\n    self._com_positions.clear()\n    self._history_hip_heights.clear()\n    self._history_com_positions.clear()\n    self._history_velocities.clear()\n    self._history_sways.clear()\n    self._history_jerks.clear()\n    self._history_body_angles.clear()\n    self._history_hand_spans.clear()\n    self._history_foot_spans.clear()\n    self._history_movement_economy.clear()\n    self._history_lock_offs.clear()\n    self._history_rest_positions.clear()\n\n    # Reset joint angle histories\n    for joint_name in self._history_joint_angles:\n        self._history_joint_angles[joint_name].clear()\n\n    self.total_frames = 0\n    self.initial_hip_height = None\n    self._total_distance_traveled = 0.0\n</code></pre>"},{"location":"api/#poseengine","title":"PoseEngine","text":"<p>Pose estimation engine using MediaPipe PoseLandmarker.</p> <p>This class wraps MediaPipe's PoseLandmarker to detect human pose landmarks in images. It provides a clean interface for processing individual frames and extracting landmark coordinates.</p> <p>Attributes:</p> Name Type Description <code>min_detection_confidence</code> <p>Minimum confidence value ([0.0, 1.0]) for pose detection to be considered successful.</p> <code>min_tracking_confidence</code> <p>Minimum confidence value ([0.0, 1.0]) for pose tracking to be considered successful.</p> <code>landmarker</code> <p>MediaPipe PoseLandmarker instance.</p> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>class PoseEngine:\n    \"\"\"Pose estimation engine using MediaPipe PoseLandmarker.\n\n    This class wraps MediaPipe's PoseLandmarker to detect human pose\n    landmarks in images. It provides a clean interface for processing\n    individual frames and extracting landmark coordinates.\n\n    Attributes:\n        min_detection_confidence: Minimum confidence value ([0.0, 1.0]) for\n            pose detection to be considered successful.\n        min_tracking_confidence: Minimum confidence value ([0.0, 1.0]) for\n            pose tracking to be considered successful.\n        landmarker: MediaPipe PoseLandmarker instance.\n    \"\"\"\n\n    def __init__(\n        self,\n        min_detection_confidence: float = PoseConfig.DEFAULT_DETECTION_CONFIDENCE,\n        min_tracking_confidence: float = PoseConfig.DEFAULT_TRACKING_CONFIDENCE,\n        model_path: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Initialize the pose engine.\n\n        Args:\n            min_detection_confidence: Minimum confidence for detection (0.0-1.0).\n            min_tracking_confidence: Minimum confidence for tracking (0.0-1.0).\n            model_path: Optional path to the pose model file. If None, downloads\n                       the default model automatically.\n        \"\"\"\n        self.min_detection_confidence = min_detection_confidence\n        self.min_tracking_confidence = min_tracking_confidence\n\n        # Get model path (download if needed)\n        if model_path is None:\n            model_path = _get_model_path()\n\n        # Create PoseLandmarker options with VIDEO mode for temporal smoothing\n        base_options = python.BaseOptions(model_asset_path=model_path)\n        options = vision.PoseLandmarkerOptions(\n            base_options=base_options,\n            running_mode=vision.RunningMode.VIDEO,  # VIDEO mode enables built-in temporal smoothing\n            min_pose_detection_confidence=min_detection_confidence,\n            min_tracking_confidence=min_tracking_confidence,\n        )\n\n        self.landmarker = vision.PoseLandmarker.create_from_options(options)\n        self._last_results = None\n        self._frame_timestamp_ms = 0  # Timestamp for VIDEO mode\n\n    def process(self, image: np.ndarray) -&gt; Optional[Any]:\n        \"\"\"Process an image and detect pose landmarks with temporal smoothing.\n\n        Args:\n            image: Input image in BGR format (OpenCV convention).\n\n        Returns:\n            MediaPipe pose detection results object containing landmarks,\n            or None if no pose was detected.\n        \"\"\"\n        # Convert BGR to RGB (MediaPipe expects RGB)\n        image_rgb = np.ascontiguousarray(image[:, :, ::-1])\n\n        # Create MediaPipe Image object\n        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n\n        # Detect pose landmarks with timestamp for VIDEO mode temporal smoothing\n        # Timestamps must increase monotonically for proper temporal filtering\n        results = self.landmarker.detect_for_video(mp_image, self._frame_timestamp_ms)\n        self._frame_timestamp_ms += PoseConfig.TIMESTAMP_INCREMENT_MS  # ~30fps\n\n        # Store results for later use\n        self._last_results = results if results.pose_landmarks else None\n\n        return self._last_results\n\n    def extract_landmarks(self, results: Any = None) -&gt; List[Dict[str, float]]:\n        \"\"\"Extract landmark coordinates from pose detection results.\n\n        Args:\n            results: MediaPipe pose detection results object. If None, uses\n                    the last processed results.\n\n        Returns:\n            List of dictionaries containing x, y, z coordinates and\n            visibility for each landmark. Coordinates are normalized\n            to [0.0, 1.0] range.\n        \"\"\"\n        if results is None:\n            results = self._last_results\n\n        if not results or not results.pose_landmarks:\n            return []\n\n        # Get first pose (PoseLandmarker can detect multiple poses)\n        pose_landmarks = results.pose_landmarks[0]\n\n        landmarks = []\n        for landmark in pose_landmarks:\n            landmarks.append(\n                {\n                    \"x\": landmark.x,\n                    \"y\": landmark.y,\n                    \"z\": landmark.z,\n                    \"visibility\": landmark.visibility,\n                }\n            )\n\n        return landmarks\n\n    def close(self) -&gt; None:\n        \"\"\"Release MediaPipe resources.\"\"\"\n        self.landmarker.close()\n\n    def __enter__(self) -&gt; \"PoseEngine\":\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n</code></pre> <p>options: show_source: true heading_level: 3</p>"},{"location":"api/#climb_sensei.pose_engine.PoseEngine.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>def __enter__(self) -&gt; \"PoseEngine\":\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#climb_sensei.pose_engine.PoseEngine.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n    \"\"\"Context manager exit.\"\"\"\n    self.close()\n</code></pre>"},{"location":"api/#climb_sensei.pose_engine.PoseEngine.__init__","title":"<code>__init__(min_detection_confidence=PoseConfig.DEFAULT_DETECTION_CONFIDENCE, min_tracking_confidence=PoseConfig.DEFAULT_TRACKING_CONFIDENCE, model_path=None)</code>","text":"<p>Initialize the pose engine.</p> <p>Parameters:</p> Name Type Description Default <code>min_detection_confidence</code> <code>float</code> <p>Minimum confidence for detection (0.0-1.0).</p> <code>DEFAULT_DETECTION_CONFIDENCE</code> <code>min_tracking_confidence</code> <code>float</code> <p>Minimum confidence for tracking (0.0-1.0).</p> <code>DEFAULT_TRACKING_CONFIDENCE</code> <code>model_path</code> <code>Optional[str]</code> <p>Optional path to the pose model file. If None, downloads        the default model automatically.</p> <code>None</code> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>def __init__(\n    self,\n    min_detection_confidence: float = PoseConfig.DEFAULT_DETECTION_CONFIDENCE,\n    min_tracking_confidence: float = PoseConfig.DEFAULT_TRACKING_CONFIDENCE,\n    model_path: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Initialize the pose engine.\n\n    Args:\n        min_detection_confidence: Minimum confidence for detection (0.0-1.0).\n        min_tracking_confidence: Minimum confidence for tracking (0.0-1.0).\n        model_path: Optional path to the pose model file. If None, downloads\n                   the default model automatically.\n    \"\"\"\n    self.min_detection_confidence = min_detection_confidence\n    self.min_tracking_confidence = min_tracking_confidence\n\n    # Get model path (download if needed)\n    if model_path is None:\n        model_path = _get_model_path()\n\n    # Create PoseLandmarker options with VIDEO mode for temporal smoothing\n    base_options = python.BaseOptions(model_asset_path=model_path)\n    options = vision.PoseLandmarkerOptions(\n        base_options=base_options,\n        running_mode=vision.RunningMode.VIDEO,  # VIDEO mode enables built-in temporal smoothing\n        min_pose_detection_confidence=min_detection_confidence,\n        min_tracking_confidence=min_tracking_confidence,\n    )\n\n    self.landmarker = vision.PoseLandmarker.create_from_options(options)\n    self._last_results = None\n    self._frame_timestamp_ms = 0  # Timestamp for VIDEO mode\n</code></pre>"},{"location":"api/#climb_sensei.pose_engine.PoseEngine.close","title":"<code>close()</code>","text":"<p>Release MediaPipe resources.</p> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Release MediaPipe resources.\"\"\"\n    self.landmarker.close()\n</code></pre>"},{"location":"api/#climb_sensei.pose_engine.PoseEngine.extract_landmarks","title":"<code>extract_landmarks(results=None)</code>","text":"<p>Extract landmark coordinates from pose detection results.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Any</code> <p>MediaPipe pose detection results object. If None, uses     the last processed results.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Dict[str, float]]</code> <p>List of dictionaries containing x, y, z coordinates and</p> <code>List[Dict[str, float]]</code> <p>visibility for each landmark. Coordinates are normalized</p> <code>List[Dict[str, float]]</code> <p>to [0.0, 1.0] range.</p> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>def extract_landmarks(self, results: Any = None) -&gt; List[Dict[str, float]]:\n    \"\"\"Extract landmark coordinates from pose detection results.\n\n    Args:\n        results: MediaPipe pose detection results object. If None, uses\n                the last processed results.\n\n    Returns:\n        List of dictionaries containing x, y, z coordinates and\n        visibility for each landmark. Coordinates are normalized\n        to [0.0, 1.0] range.\n    \"\"\"\n    if results is None:\n        results = self._last_results\n\n    if not results or not results.pose_landmarks:\n        return []\n\n    # Get first pose (PoseLandmarker can detect multiple poses)\n    pose_landmarks = results.pose_landmarks[0]\n\n    landmarks = []\n    for landmark in pose_landmarks:\n        landmarks.append(\n            {\n                \"x\": landmark.x,\n                \"y\": landmark.y,\n                \"z\": landmark.z,\n                \"visibility\": landmark.visibility,\n            }\n        )\n\n    return landmarks\n</code></pre>"},{"location":"api/#climb_sensei.pose_engine.PoseEngine.process","title":"<code>process(image)</code>","text":"<p>Process an image and detect pose landmarks with temporal smoothing.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>Input image in BGR format (OpenCV convention).</p> required <p>Returns:</p> Type Description <code>Optional[Any]</code> <p>MediaPipe pose detection results object containing landmarks,</p> <code>Optional[Any]</code> <p>or None if no pose was detected.</p> Source code in <code>src/climb_sensei/pose_engine.py</code> <pre><code>def process(self, image: np.ndarray) -&gt; Optional[Any]:\n    \"\"\"Process an image and detect pose landmarks with temporal smoothing.\n\n    Args:\n        image: Input image in BGR format (OpenCV convention).\n\n    Returns:\n        MediaPipe pose detection results object containing landmarks,\n        or None if no pose was detected.\n    \"\"\"\n    # Convert BGR to RGB (MediaPipe expects RGB)\n    image_rgb = np.ascontiguousarray(image[:, :, ::-1])\n\n    # Create MediaPipe Image object\n    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n\n    # Detect pose landmarks with timestamp for VIDEO mode temporal smoothing\n    # Timestamps must increase monotonically for proper temporal filtering\n    results = self.landmarker.detect_for_video(mp_image, self._frame_timestamp_ms)\n    self._frame_timestamp_ms += PoseConfig.TIMESTAMP_INCREMENT_MS  # ~30fps\n\n    # Store results for later use\n    self._last_results = results if results.pose_landmarks else None\n\n    return self._last_results\n</code></pre>"},{"location":"api/#videoreader","title":"VideoReader","text":"<p>Read video frames from a file or camera source.</p> <p>Attributes:</p> Name Type Description <code>path</code> <p>Path to video file or camera index.</p> <code>cap</code> <p>OpenCV VideoCapture object.</p> <code>fps</code> <p>Frames per second of the video.</p> <code>frame_count</code> <p>Total number of frames in the video.</p> <code>width</code> <p>Width of video frames in pixels.</p> <code>height</code> <p>Height of video frames in pixels.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>class VideoReader:\n    \"\"\"Read video frames from a file or camera source.\n\n    Attributes:\n        path: Path to video file or camera index.\n        cap: OpenCV VideoCapture object.\n        fps: Frames per second of the video.\n        frame_count: Total number of frames in the video.\n        width: Width of video frames in pixels.\n        height: Height of video frames in pixels.\n    \"\"\"\n\n    def __init__(self, path: str | int) -&gt; None:\n        \"\"\"Initialize the video reader.\n\n        Args:\n            path: Path to video file or camera index (0 for default camera).\n\n        Raises:\n            ValueError: If the video source cannot be opened.\n        \"\"\"\n        self.path = path\n        self.cap = cv2.VideoCapture(path)\n\n        if not self.cap.isOpened():\n            raise ValueError(f\"Cannot open video source: {path}\")\n\n        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    def read(self) -&gt; Tuple[bool, Optional[np.ndarray]]:\n        \"\"\"Read the next frame from the video.\n\n        Returns:\n            A tuple of (success, frame) where success is True if frame was read\n            successfully, and frame is the image data as a numpy array.\n        \"\"\"\n        success, frame = self.cap.read()\n        return success, frame if success else None\n\n    def release(self) -&gt; None:\n        \"\"\"Release the video capture resource.\"\"\"\n        self.cap.release()\n\n    def __enter__(self) -&gt; \"VideoReader\":\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n        \"\"\"Context manager exit.\"\"\"\n        self.release()\n</code></pre> <p>options: show_source: true heading_level: 3</p>"},{"location":"api/#climb_sensei.video_io.VideoReader.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def __enter__(self) -&gt; \"VideoReader\":\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoReader.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n    \"\"\"Context manager exit.\"\"\"\n    self.release()\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoReader.__init__","title":"<code>__init__(path)</code>","text":"<p>Initialize the video reader.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | int</code> <p>Path to video file or camera index (0 for default camera).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video source cannot be opened.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def __init__(self, path: str | int) -&gt; None:\n    \"\"\"Initialize the video reader.\n\n    Args:\n        path: Path to video file or camera index (0 for default camera).\n\n    Raises:\n        ValueError: If the video source cannot be opened.\n    \"\"\"\n    self.path = path\n    self.cap = cv2.VideoCapture(path)\n\n    if not self.cap.isOpened():\n        raise ValueError(f\"Cannot open video source: {path}\")\n\n    self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n    self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoReader.read","title":"<code>read()</code>","text":"<p>Read the next frame from the video.</p> <p>Returns:</p> Type Description <code>bool</code> <p>A tuple of (success, frame) where success is True if frame was read</p> <code>Optional[ndarray]</code> <p>successfully, and frame is the image data as a numpy array.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def read(self) -&gt; Tuple[bool, Optional[np.ndarray]]:\n    \"\"\"Read the next frame from the video.\n\n    Returns:\n        A tuple of (success, frame) where success is True if frame was read\n        successfully, and frame is the image data as a numpy array.\n    \"\"\"\n    success, frame = self.cap.read()\n    return success, frame if success else None\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoReader.release","title":"<code>release()</code>","text":"<p>Release the video capture resource.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def release(self) -&gt; None:\n    \"\"\"Release the video capture resource.\"\"\"\n    self.cap.release()\n</code></pre>"},{"location":"api/#videowriter","title":"VideoWriter","text":"<p>Write video frames to a file.</p> <p>Attributes:</p> Name Type Description <code>path</code> <p>Output file path.</p> <code>fourcc</code> <p>FourCC codec code.</p> <code>fps</code> <p>Frames per second for output video.</p> <code>width</code> <p>Width of output frames in pixels.</p> <code>height</code> <p>Height of output frames in pixels.</p> <code>writer</code> <p>OpenCV VideoWriter object.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>class VideoWriter:\n    \"\"\"Write video frames to a file.\n\n    Attributes:\n        path: Output file path.\n        fourcc: FourCC codec code.\n        fps: Frames per second for output video.\n        width: Width of output frames in pixels.\n        height: Height of output frames in pixels.\n        writer: OpenCV VideoWriter object.\n    \"\"\"\n\n    def __init__(\n        self, path: str, fps: int, width: int, height: int, fourcc: str = \"mp4v\"\n    ) -&gt; None:\n        \"\"\"Initialize the video writer.\n\n        Args:\n            path: Output file path.\n            fps: Frames per second for the output video.\n            width: Width of output frames in pixels.\n            height: Height of output frames in pixels.\n            fourcc: FourCC codec code (default: \"mp4v\").\n\n        Raises:\n            ValueError: If the video writer cannot be initialized.\n        \"\"\"\n        self.path = path\n        self.fps = fps\n        self.width = width\n        self.height = height\n        self.fourcc = cv2.VideoWriter_fourcc(*fourcc)\n\n        self.writer = cv2.VideoWriter(path, self.fourcc, fps, (width, height))\n\n        if not self.writer.isOpened():\n            raise ValueError(f\"Cannot open video writer for: {path}\")\n\n    def write(self, frame: np.ndarray) -&gt; None:\n        \"\"\"Write a frame to the video file.\n\n        Args:\n            frame: Image data as a numpy array (BGR format).\n        \"\"\"\n        self.writer.write(frame)\n\n    def release(self) -&gt; None:\n        \"\"\"Release the video writer resource.\"\"\"\n        self.writer.release()\n\n    def __enter__(self) -&gt; \"VideoWriter\":\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n        \"\"\"Context manager exit.\"\"\"\n        self.release()\n</code></pre> <p>options: show_source: true heading_level: 3</p>"},{"location":"api/#climb_sensei.video_io.VideoWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def __enter__(self) -&gt; \"VideoWriter\":\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoWriter.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb) -&gt; None:\n    \"\"\"Context manager exit.\"\"\"\n    self.release()\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoWriter.__init__","title":"<code>__init__(path, fps, width, height, fourcc='mp4v')</code>","text":"<p>Initialize the video writer.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output file path.</p> required <code>fps</code> <code>int</code> <p>Frames per second for the output video.</p> required <code>width</code> <code>int</code> <p>Width of output frames in pixels.</p> required <code>height</code> <code>int</code> <p>Height of output frames in pixels.</p> required <code>fourcc</code> <code>str</code> <p>FourCC codec code (default: \"mp4v\").</p> <code>'mp4v'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video writer cannot be initialized.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def __init__(\n    self, path: str, fps: int, width: int, height: int, fourcc: str = \"mp4v\"\n) -&gt; None:\n    \"\"\"Initialize the video writer.\n\n    Args:\n        path: Output file path.\n        fps: Frames per second for the output video.\n        width: Width of output frames in pixels.\n        height: Height of output frames in pixels.\n        fourcc: FourCC codec code (default: \"mp4v\").\n\n    Raises:\n        ValueError: If the video writer cannot be initialized.\n    \"\"\"\n    self.path = path\n    self.fps = fps\n    self.width = width\n    self.height = height\n    self.fourcc = cv2.VideoWriter_fourcc(*fourcc)\n\n    self.writer = cv2.VideoWriter(path, self.fourcc, fps, (width, height))\n\n    if not self.writer.isOpened():\n        raise ValueError(f\"Cannot open video writer for: {path}\")\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoWriter.release","title":"<code>release()</code>","text":"<p>Release the video writer resource.</p> Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def release(self) -&gt; None:\n    \"\"\"Release the video writer resource.\"\"\"\n    self.writer.release()\n</code></pre>"},{"location":"api/#climb_sensei.video_io.VideoWriter.write","title":"<code>write(frame)</code>","text":"<p>Write a frame to the video file.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Image data as a numpy array (BGR format).</p> required Source code in <code>src/climb_sensei/video_io.py</code> <pre><code>def write(self, frame: np.ndarray) -&gt; None:\n    \"\"\"Write a frame to the video file.\n\n    Args:\n        frame: Image data as a numpy array (BGR format).\n    \"\"\"\n    self.writer.write(frame)\n</code></pre>"},{"location":"api/#biomechanics-functions","title":"Biomechanics Functions","text":""},{"location":"api/#calculate_joint_angle","title":"calculate_joint_angle","text":"<p>Calculate the angle at point B formed by three points A-B-C.</p> <p>This function calculates the interior angle at the middle point (B) using the law of cosines. The angle is measured in degrees.</p> <p>Parameters:</p> Name Type Description Default <code>point_a</code> <code>Tuple[float, float]</code> <p>Coordinates (x, y) of the first point.</p> required <code>point_b</code> <code>Tuple[float, float]</code> <p>Coordinates (x, y) of the vertex point (angle point).</p> required <code>point_c</code> <code>Tuple[float, float]</code> <p>Coordinates (x, y) of the third point.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Angle in degrees at point B (range: 0-180).</p> Example Source code in <code>src/climb_sensei/biomechanics.py</code> <pre><code>def calculate_joint_angle(\n    point_a: Tuple[float, float],\n    point_b: Tuple[float, float],\n    point_c: Tuple[float, float],\n) -&gt; float:\n    \"\"\"Calculate the angle at point B formed by three points A-B-C.\n\n    This function calculates the interior angle at the middle point (B)\n    using the law of cosines. The angle is measured in degrees.\n\n    Args:\n        point_a: Coordinates (x, y) of the first point.\n        point_b: Coordinates (x, y) of the vertex point (angle point).\n        point_c: Coordinates (x, y) of the third point.\n\n    Returns:\n        Angle in degrees at point B (range: 0-180).\n\n    Example:\n        &gt;&gt;&gt; # Calculate elbow angle\n        &gt;&gt;&gt; shoulder = (0.5, 0.3)\n        &gt;&gt;&gt; elbow = (0.6, 0.5)\n        &gt;&gt;&gt; wrist = (0.7, 0.6)\n        &gt;&gt;&gt; angle = calculate_joint_angle(shoulder, elbow, wrist)\n    \"\"\"\n    # Calculate vectors BA and BC\n    ba_x = point_a[0] - point_b[0]\n    ba_y = point_a[1] - point_b[1]\n    bc_x = point_c[0] - point_b[0]\n    bc_y = point_c[1] - point_b[1]\n\n    # Calculate dot product\n    dot_product = ba_x * bc_x + ba_y * bc_y\n\n    # Calculate magnitudes\n    magnitude_ba = math.sqrt(ba_x**2 + ba_y**2)\n    magnitude_bc = math.sqrt(bc_x**2 + bc_y**2)\n\n    # Avoid division by zero\n    if magnitude_ba == 0 or magnitude_bc == 0:\n        return 0.0\n\n    # Calculate angle using dot product formula\n    cos_angle = dot_product / (magnitude_ba * magnitude_bc)\n\n    # Clamp to valid range for arccos\n    cos_angle = max(-1.0, min(1.0, cos_angle))\n\n    # Convert to degrees\n    angle_radians = math.acos(cos_angle)\n    angle_degrees = math.degrees(angle_radians)\n\n    return angle_degrees\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#climb_sensei.biomechanics.calculate_joint_angle--calculate-elbow-angle","title":"Calculate elbow angle","text":"<p>shoulder = (0.5, 0.3) elbow = (0.6, 0.5) wrist = (0.7, 0.6) angle = calculate_joint_angle(shoulder, elbow, wrist)</p>"},{"location":"api/#calculate_reach_distance","title":"calculate_reach_distance","text":"<p>Calculate Euclidean distance between two points.</p> <p>This function calculates the straight-line distance between two points in 2D space. Useful for measuring reach distances between body landmarks.</p> <p>Parameters:</p> Name Type Description Default <code>point_a</code> <code>Tuple[float, float]</code> <p>Coordinates (x, y) of the first point.</p> required <code>point_b</code> <code>Tuple[float, float]</code> <p>Coordinates (x, y) of the second point.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Euclidean distance between the two points.</p> Example Source code in <code>src/climb_sensei/biomechanics.py</code> <pre><code>def calculate_reach_distance(\n    point_a: Tuple[float, float], point_b: Tuple[float, float]\n) -&gt; float:\n    \"\"\"Calculate Euclidean distance between two points.\n\n    This function calculates the straight-line distance between two\n    points in 2D space. Useful for measuring reach distances between\n    body landmarks.\n\n    Args:\n        point_a: Coordinates (x, y) of the first point.\n        point_b: Coordinates (x, y) of the second point.\n\n    Returns:\n        Euclidean distance between the two points.\n\n    Example:\n        &gt;&gt;&gt; # Calculate reach from hip to hand\n        &gt;&gt;&gt; hip = (0.5, 0.5)\n        &gt;&gt;&gt; hand = (0.7, 0.3)\n        &gt;&gt;&gt; distance = calculate_reach_distance(hip, hand)\n    \"\"\"\n    dx = point_b[0] - point_a[0]\n    dy = point_b[1] - point_a[1]\n\n    distance = math.sqrt(dx**2 + dy**2)\n\n    return distance\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#climb_sensei.biomechanics.calculate_reach_distance--calculate-reach-from-hip-to-hand","title":"Calculate reach from hip to hand","text":"<p>hip = (0.5, 0.5) hand = (0.7, 0.3) distance = calculate_reach_distance(hip, hand)</p>"},{"location":"api/#calculate_center_of_mass","title":"calculate_center_of_mass","text":"<p>Calculate the weighted center of mass for a set of points.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>list[Tuple[float, float]]</code> <p>List of (x, y) coordinate tuples.</p> required <code>weights</code> <code>list[float] | None</code> <p>Optional list of weights for each point. If None, all points are weighted equally.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Coordinates (x, y) of the center of mass.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If points list is empty or weights length doesn't match.</p> Example Source code in <code>src/climb_sensei/biomechanics.py</code> <pre><code>def calculate_center_of_mass(\n    points: list[Tuple[float, float]], weights: list[float] | None = None\n) -&gt; Tuple[float, float]:\n    \"\"\"Calculate the weighted center of mass for a set of points.\n\n    Args:\n        points: List of (x, y) coordinate tuples.\n        weights: Optional list of weights for each point. If None, all\n            points are weighted equally.\n\n    Returns:\n        Coordinates (x, y) of the center of mass.\n\n    Raises:\n        ValueError: If points list is empty or weights length doesn't match.\n\n    Example:\n        &gt;&gt;&gt; # Calculate body center of mass\n        &gt;&gt;&gt; landmarks = [(0.5, 0.3), (0.5, 0.5), (0.5, 0.7)]\n        &gt;&gt;&gt; center = calculate_center_of_mass(landmarks)\n    \"\"\"\n    if not points:\n        raise ValueError(\"Points list cannot be empty\")\n\n    if weights is None:\n        weights = [1.0] * len(points)\n\n    if len(points) != len(weights):\n        raise ValueError(\"Points and weights must have the same length\")\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        raise ValueError(\"Total weight cannot be zero\")\n\n    weighted_x = sum(p[0] * w for p, w in zip(points, weights))\n    weighted_y = sum(p[1] * w for p, w in zip(points, weights))\n\n    center_x = weighted_x / total_weight\n    center_y = weighted_y / total_weight\n\n    return (center_x, center_y)\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#climb_sensei.biomechanics.calculate_center_of_mass--calculate-body-center-of-mass","title":"Calculate body center of mass","text":"<p>landmarks = [(0.5, 0.3), (0.5, 0.5), (0.5, 0.7)] center = calculate_center_of_mass(landmarks)</p>"},{"location":"api/#calculate_limb_angles","title":"calculate_limb_angles","text":"<p>Calculate joint angles for all major limbs.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>list[dict[str, float]]</code> <p>List of landmark dictionaries with x, y, z coordinates</p> required <code>landmark_indices</code> <code>object</code> <p>LandmarkIndex class with landmark indices</p> required <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary with joint angles:</p> <code>dict[str, float]</code> <ul> <li>left_elbow: Left elbow angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>right_elbow: Right elbow angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>left_shoulder: Left shoulder angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>right_shoulder: Right shoulder angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>left_knee: Left knee angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>right_knee: Right knee angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>left_hip: Left hip angle (degrees)</li> </ul> <code>dict[str, float]</code> <ul> <li>right_hip: Right hip angle (degrees)</li> </ul> Source code in <code>src/climb_sensei/biomechanics.py</code> <pre><code>def calculate_limb_angles(\n    landmarks: list[dict[str, float]], landmark_indices: object\n) -&gt; dict[str, float]:\n    \"\"\"Calculate joint angles for all major limbs.\n\n    Args:\n        landmarks: List of landmark dictionaries with x, y, z coordinates\n        landmark_indices: LandmarkIndex class with landmark indices\n\n    Returns:\n        Dictionary with joint angles:\n        - left_elbow: Left elbow angle (degrees)\n        - right_elbow: Right elbow angle (degrees)\n        - left_shoulder: Left shoulder angle (degrees)\n        - right_shoulder: Right shoulder angle (degrees)\n        - left_knee: Left knee angle (degrees)\n        - right_knee: Right knee angle (degrees)\n        - left_hip: Left hip angle (degrees)\n        - right_hip: Right hip angle (degrees)\n    \"\"\"\n    if len(landmarks) &lt; 33:\n        return {}\n\n    angles = {}\n\n    # Elbow angles\n    angles[\"left_elbow\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.LEFT_SHOULDER][\"x\"],\n            landmarks[landmark_indices.LEFT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_ELBOW][\"x\"],\n            landmarks[landmark_indices.LEFT_ELBOW][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_WRIST][\"x\"],\n            landmarks[landmark_indices.LEFT_WRIST][\"y\"],\n        ),\n    )\n\n    angles[\"right_elbow\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.RIGHT_SHOULDER][\"x\"],\n            landmarks[landmark_indices.RIGHT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_ELBOW][\"x\"],\n            landmarks[landmark_indices.RIGHT_ELBOW][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_WRIST][\"x\"],\n            landmarks[landmark_indices.RIGHT_WRIST][\"y\"],\n        ),\n    )\n\n    # Shoulder angles\n    angles[\"left_shoulder\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.LEFT_HIP][\"x\"],\n            landmarks[landmark_indices.LEFT_HIP][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_SHOULDER][\"x\"],\n            landmarks[landmark_indices.LEFT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_ELBOW][\"x\"],\n            landmarks[landmark_indices.LEFT_ELBOW][\"y\"],\n        ),\n    )\n\n    angles[\"right_shoulder\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.RIGHT_HIP][\"x\"],\n            landmarks[landmark_indices.RIGHT_HIP][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_SHOULDER][\"x\"],\n            landmarks[landmark_indices.RIGHT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_ELBOW][\"x\"],\n            landmarks[landmark_indices.RIGHT_ELBOW][\"y\"],\n        ),\n    )\n\n    # Knee angles\n    angles[\"left_knee\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.LEFT_HIP][\"x\"],\n            landmarks[landmark_indices.LEFT_HIP][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_KNEE][\"x\"],\n            landmarks[landmark_indices.LEFT_KNEE][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_ANKLE][\"x\"],\n            landmarks[landmark_indices.LEFT_ANKLE][\"y\"],\n        ),\n    )\n\n    angles[\"right_knee\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.RIGHT_HIP][\"x\"],\n            landmarks[landmark_indices.RIGHT_HIP][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_KNEE][\"x\"],\n            landmarks[landmark_indices.RIGHT_KNEE][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_ANKLE][\"x\"],\n            landmarks[landmark_indices.RIGHT_ANKLE][\"y\"],\n        ),\n    )\n\n    # Hip angles\n    angles[\"left_hip\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.LEFT_SHOULDER][\"x\"],\n            landmarks[landmark_indices.LEFT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_HIP][\"x\"],\n            landmarks[landmark_indices.LEFT_HIP][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.LEFT_KNEE][\"x\"],\n            landmarks[landmark_indices.LEFT_KNEE][\"y\"],\n        ),\n    )\n\n    angles[\"right_hip\"] = calculate_joint_angle(\n        (\n            landmarks[landmark_indices.RIGHT_SHOULDER][\"x\"],\n            landmarks[landmark_indices.RIGHT_SHOULDER][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_HIP][\"x\"],\n            landmarks[landmark_indices.RIGHT_HIP][\"y\"],\n        ),\n        (\n            landmarks[landmark_indices.RIGHT_KNEE][\"x\"],\n            landmarks[landmark_indices.RIGHT_KNEE][\"y\"],\n        ),\n    )\n\n    return angles\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#calculate_total_distance_traveled","title":"calculate_total_distance_traveled","text":"<p>Calculate total distance traveled along a path.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>list[Tuple[float, float]]</code> <p>List of (x, y) positions in chronological order</p> required <p>Returns:</p> Type Description <code>float</code> <p>Total distance traveled (sum of all segments)</p> Source code in <code>src/climb_sensei/biomechanics.py</code> <pre><code>def calculate_total_distance_traveled(positions: list[Tuple[float, float]]) -&gt; float:\n    \"\"\"Calculate total distance traveled along a path.\n\n    Args:\n        positions: List of (x, y) positions in chronological order\n\n    Returns:\n        Total distance traveled (sum of all segments)\n    \"\"\"\n    if len(positions) &lt; 2:\n        return 0.0\n\n    total_distance = 0.0\n    for i in range(1, len(positions)):\n        total_distance += calculate_reach_distance(positions[i - 1], positions[i])\n\n    return total_distance\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#visualization-functions","title":"Visualization Functions","text":""},{"location":"api/#draw_pose_landmarks","title":"draw_pose_landmarks","text":"<p>Draw pose landmarks and connections on an image with color-coded body parts.</p> <p>This function draws the detected pose landmarks as circles and connects them with lines. By default, uses color-coding for different body parts (similar to MediaPipe's built-in visualization).</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>Input image in BGR format (will not be modified).</p> required <code>results</code> <code>Any</code> <p>MediaPipe pose detection results object.</p> required <code>landmark_color</code> <code>Optional[Tuple[int, int, int]]</code> <p>BGR color tuple for landmarks. If None and use_color_coding=True,            uses automatic color-coding by body part.</p> <code>None</code> <code>connection_color</code> <code>Optional[Tuple[int, int, int]]</code> <p>BGR color tuple for connections. If None, uses white.</p> <code>None</code> <code>thickness</code> <code>int</code> <p>Line thickness in pixels (default: 2).</p> <code>DEFAULT_LINE_THICKNESS</code> <code>circle_radius</code> <code>int</code> <p>Landmark circle radius in pixels (default: 5).</p> <code>DEFAULT_CIRCLE_RADIUS</code> <code>connections</code> <code>Optional[FrozenSet[Tuple[int, int]]]</code> <p>Optional set of (start_idx, end_idx) tuples defining which         landmarks to connect. If None, uses default full pose connections.</p> <code>None</code> <code>landmarks_to_draw</code> <code>Optional[FrozenSet[int]]</code> <p>Optional set of landmark indices to draw. If None, draws all.</p> <code>None</code> <code>use_color_coding</code> <code>bool</code> <p>If True, uses color-coded landmarks by body part (default: True).</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>New image with landmarks drawn (BGR format).</p> Example <p>from climb_sensei.config import CLIMBING_CONNECTIONS, CLIMBING_LANDMARKS with PoseEngine() as engine: ...     results = engine.process(frame) ...     if results: ...         # Draw only climbing-relevant landmarks (no head) with color-coding ...         annotated_frame = draw_pose_landmarks( ...             frame, results, ...             connections=CLIMBING_CONNECTIONS, ...             landmarks_to_draw=CLIMBING_LANDMARKS ...         )</p> Source code in <code>src/climb_sensei/viz.py</code> <pre><code>def draw_pose_landmarks(\n    image: np.ndarray,\n    results: Any,\n    landmark_color: Optional[Tuple[int, int, int]] = None,\n    connection_color: Optional[Tuple[int, int, int]] = None,\n    thickness: int = VisualizationConfig.DEFAULT_LINE_THICKNESS,\n    circle_radius: int = VisualizationConfig.DEFAULT_CIRCLE_RADIUS,\n    connections: Optional[FrozenSet[Tuple[int, int]]] = None,\n    landmarks_to_draw: Optional[FrozenSet[int]] = None,\n    use_color_coding: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Draw pose landmarks and connections on an image with color-coded body parts.\n\n    This function draws the detected pose landmarks as circles and\n    connects them with lines. By default, uses color-coding for different\n    body parts (similar to MediaPipe's built-in visualization).\n\n    Args:\n        image: Input image in BGR format (will not be modified).\n        results: MediaPipe pose detection results object.\n        landmark_color: BGR color tuple for landmarks. If None and use_color_coding=True,\n                       uses automatic color-coding by body part.\n        connection_color: BGR color tuple for connections. If None, uses white.\n        thickness: Line thickness in pixels (default: 2).\n        circle_radius: Landmark circle radius in pixels (default: 5).\n        connections: Optional set of (start_idx, end_idx) tuples defining which\n                    landmarks to connect. If None, uses default full pose connections.\n        landmarks_to_draw: Optional set of landmark indices to draw. If None, draws all.\n        use_color_coding: If True, uses color-coded landmarks by body part (default: True).\n\n    Returns:\n        New image with landmarks drawn (BGR format).\n\n    Example:\n        &gt;&gt;&gt; from climb_sensei.config import CLIMBING_CONNECTIONS, CLIMBING_LANDMARKS\n        &gt;&gt;&gt; with PoseEngine() as engine:\n        ...     results = engine.process(frame)\n        ...     if results:\n        ...         # Draw only climbing-relevant landmarks (no head) with color-coding\n        ...         annotated_frame = draw_pose_landmarks(\n        ...             frame, results,\n        ...             connections=CLIMBING_CONNECTIONS,\n        ...             landmarks_to_draw=CLIMBING_LANDMARKS\n        ...         )\n    \"\"\"\n    # Create a copy to avoid modifying the original\n    annotated_image = image.copy()\n\n    if not results or not results.pose_landmarks:\n        return annotated_image\n\n    # Use default connections if none provided\n    if connections is None:\n        connections = _POSE_CONNECTIONS\n\n    # Default connection color\n    if connection_color is None:\n        connection_color = VisualizationConfig.COLORS[\"connection\"]\n\n    # Extract landmarks from results\n    pose_landmarks = results.pose_landmarks[0]\n    h, w = image.shape[:2]\n\n    # Convert landmarks to pixel coordinates\n    landmark_points = []\n    for landmark in pose_landmarks:\n        x = int(landmark.x * w)\n        y = int(landmark.y * h)\n        landmark_points.append((x, y))\n\n    # Draw connections\n    for connection in connections:\n        start_idx, end_idx = connection\n        # Only draw connection if both landmarks are in the filter set (or no filter)\n        if landmarks_to_draw is None or (\n            start_idx in landmarks_to_draw and end_idx in landmarks_to_draw\n        ):\n            if start_idx &lt; len(landmark_points) and end_idx &lt; len(landmark_points):\n                start_point = landmark_points[start_idx]\n                end_point = landmark_points[end_idx]\n                cv2.line(\n                    annotated_image, start_point, end_point, connection_color, thickness\n                )\n\n    # Draw landmarks\n    for idx, point in enumerate(landmark_points):\n        # Only draw if landmark is in the set to draw (or if no filter is specified)\n        if landmarks_to_draw is None or idx in landmarks_to_draw:\n            # Determine color\n            if use_color_coding and landmark_color is None:\n                color = _get_landmark_color(idx)\n            else:\n                color = landmark_color if landmark_color else (0, 255, 0)\n\n            cv2.circle(annotated_image, point, circle_radius, color, -1)\n            # Add small border for better visibility\n            cv2.circle(\n                annotated_image,\n                point,\n                circle_radius,\n                VisualizationConfig.COLORS[\"connection\"],\n                VisualizationConfig.LANDMARK_BORDER_THICKNESS,\n            )\n\n    return annotated_image\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#draw_metrics_overlay","title":"draw_metrics_overlay","text":"<p>Draw climbing metrics overlay on image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>Input image in BGR format (will not be modified).</p> required <code>current_metrics</code> <code>Optional[dict]</code> <p>Dictionary of current frame metrics.</p> <code>None</code> <code>cumulative_metrics</code> <code>Optional[dict]</code> <p>Dictionary of cumulative/average metrics.</p> <code>None</code> <code>font_scale</code> <code>float</code> <p>Font scale factor (default: 0.6).</p> <code>DEFAULT_FONT_SCALE</code> <code>thickness</code> <code>int</code> <p>Text thickness in pixels (default: 2).</p> <code>DEFAULT_FONT_THICKNESS</code> <code>bg_alpha</code> <code>float</code> <p>Background transparency (0.0-1.0, default: 0.7).</p> <code>METRICS_OVERLAY_BG_ALPHA</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>New image with metrics overlay drawn (BGR format).</p> Source code in <code>src/climb_sensei/viz.py</code> <pre><code>def draw_metrics_overlay(\n    image: np.ndarray,\n    current_metrics: Optional[dict] = None,\n    cumulative_metrics: Optional[dict] = None,\n    font_scale: float = VisualizationConfig.DEFAULT_FONT_SCALE,\n    thickness: int = VisualizationConfig.DEFAULT_FONT_THICKNESS,\n    bg_alpha: float = VisualizationConfig.METRICS_OVERLAY_BG_ALPHA,\n) -&gt; np.ndarray:\n    \"\"\"Draw climbing metrics overlay on image.\n\n    Args:\n        image: Input image in BGR format (will not be modified).\n        current_metrics: Dictionary of current frame metrics.\n        cumulative_metrics: Dictionary of cumulative/average metrics.\n        font_scale: Font scale factor (default: 0.6).\n        thickness: Text thickness in pixels (default: 2).\n        bg_alpha: Background transparency (0.0-1.0, default: 0.7).\n\n    Returns:\n        New image with metrics overlay drawn (BGR format).\n    \"\"\"\n    annotated_image = image.copy()\n    h, w = image.shape[:2]\n\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    line_height = int(VisualizationConfig.METRICS_LINE_HEIGHT * font_scale)\n    padding = VisualizationConfig.METRICS_OVERLAY_PADDING\n\n    # Prepare text lines\n    lines = []\n\n    if current_metrics:\n        lines.append((\"CURRENT FRAME\", (0, 255, 255)))  # Yellow\n        lines.append((f\"Frame: {current_metrics.get('frame', 0)}\", (255, 255, 255)))\n        lines.append(\n            (\n                f\"L Elbow: {current_metrics.get('left_elbow_angle', 0):.1f}\u00b0\",\n                (100, 255, 100),\n            )\n        )\n        lines.append(\n            (\n                f\"R Elbow: {current_metrics.get('right_elbow_angle', 0):.1f}\u00b0\",\n                (100, 255, 100),\n            )\n        )\n        lines.append(\n            (\n                f\"L Knee: {current_metrics.get('left_knee_angle', 0):.1f}\u00b0\",\n                (100, 200, 255),\n            )\n        )\n        lines.append(\n            (\n                f\"R Knee: {current_metrics.get('right_knee_angle', 0):.1f}\u00b0\",\n                (100, 200, 255),\n            )\n        )\n        lines.append(\n            (f\"Max Reach: {current_metrics.get('max_reach', 0):.3f}\", (255, 150, 100))\n        )\n\n        # Lock-off indicators\n        if current_metrics.get(\"left_lock_off\"):\n            lines.append((\"L LOCK-OFF\", (0, 0, 255)))\n        if current_metrics.get(\"right_lock_off\"):\n            lines.append((\"R LOCK-OFF\", (0, 0, 255)))\n\n    if cumulative_metrics and lines:\n        lines.append((\"\", (255, 255, 255)))  # Spacer\n\n    if cumulative_metrics:\n        lines.append((\"AVERAGES\", (0, 255, 255)))  # Yellow\n        lines.append(\n            (\n                f\"L Elbow: {cumulative_metrics.get('avg_left_elbow', 0):.1f}\u00b0\",\n                (150, 255, 150),\n            )\n        )\n        lines.append(\n            (\n                f\"R Elbow: {cumulative_metrics.get('avg_right_elbow', 0):.1f}\u00b0\",\n                (150, 255, 150),\n            )\n        )\n        lines.append(\n            (\n                f\"Max Reach: {cumulative_metrics.get('avg_max_reach', 0):.3f}\",\n                (255, 180, 150),\n            )\n        )\n        lines.append(\n            (\n                f\"Extension: {cumulative_metrics.get('avg_extension', 0):.3f}\",\n                (200, 200, 255),\n            )\n        )\n\n    if not lines:\n        return annotated_image\n\n    # Calculate overlay dimensions\n    max_text_width = 0\n    for text, _ in lines:\n        if text:\n            (text_w, text_h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n            max_text_width = max(max_text_width, text_w)\n\n    overlay_width = max_text_width + 2 * padding\n    overlay_height = len(lines) * line_height + 2 * padding\n\n    # Create semi-transparent background\n    overlay = annotated_image.copy()\n    x1, y1 = padding, padding\n    x2, y2 = x1 + overlay_width, y1 + overlay_height\n\n    cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 0), -1)\n    cv2.addWeighted(\n        overlay, bg_alpha, annotated_image, 1 - bg_alpha, 0, annotated_image\n    )\n\n    # Draw text\n    y_offset = y1 + padding + line_height\n    for text, color in lines:\n        if text:  # Skip empty lines for spacing\n            cv2.putText(\n                annotated_image,\n                text,\n                (x1 + padding, y_offset),\n                font,\n                font_scale,\n                color,\n                thickness,\n                cv2.LINE_AA,\n            )\n        y_offset += line_height\n\n    return annotated_image\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#create_metrics_dashboard","title":"create_metrics_dashboard","text":"<p>Create a dashboard with multiple metric plots.</p> <p>Parameters:</p> Name Type Description Default <code>history</code> <code>Dict[str, List[float]]</code> <p>Dictionary with metric histories from ClimbingAnalyzer.get_history()</p> required <code>current_frame</code> <code>int</code> <p>Current frame index</p> required <code>fps</code> <code>float</code> <p>Frames per second (for time axis)</p> <code>30.0</code> <code>plot_width</code> <code>int</code> <p>Width of each plot</p> <code>PLOT_WIDTH</code> <code>plot_height</code> <code>int</code> <p>Height of each plot</p> <code>PLOT_HEIGHT</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Dashboard image as numpy array (BGR format)</p> Source code in <code>src/climb_sensei/metrics_viz.py</code> <pre><code>def create_metrics_dashboard(\n    history: Dict[str, List[float]],\n    current_frame: int,\n    fps: float = 30.0,\n    plot_width: int = VisualizationConfig.PLOT_WIDTH,\n    plot_height: int = VisualizationConfig.PLOT_HEIGHT,\n) -&gt; np.ndarray:\n    \"\"\"Create a dashboard with multiple metric plots.\n\n    Args:\n        history: Dictionary with metric histories from ClimbingAnalyzer.get_history()\n        current_frame: Current frame index\n        fps: Frames per second (for time axis)\n        plot_width: Width of each plot\n        plot_height: Height of each plot\n\n    Returns:\n        Dashboard image as numpy array (BGR format)\n    \"\"\"\n    plots = []\n\n    # Vertical progress (inverted - climbing up)\n    if history.get(\"hip_heights\"):\n        hip_heights = history[\"hip_heights\"]\n        initial = hip_heights[0] if hip_heights else 0\n        progress = [initial - h for h in hip_heights]\n        plot = create_metric_plot(\n            progress,\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Vertical Progress\",\n            color=(0, 255, 255),\n            y_label=\"height\",\n            min_val=0,\n        )\n        plots.append(plot)\n\n    # Velocity\n    if history.get(\"velocities\"):\n        plot = create_metric_plot(\n            history[\"velocities\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Movement Speed\",\n            color=(0, 255, 0),\n            y_label=\"vel\",\n            min_val=0,\n        )\n        plots.append(plot)\n\n    # Stability (sway)\n    if history.get(\"sways\"):\n        plot = create_metric_plot(\n            history[\"sways\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Lateral Sway (stability)\",\n            color=(255, 128, 0),\n            y_label=\"sway\",\n            min_val=0,\n        )\n        plots.append(plot)\n\n    # Smoothness (jerk - lower is better)\n    if history.get(\"jerks\"):\n        plot = create_metric_plot(\n            history[\"jerks\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Jerk (smoothness)\",\n            color=(255, 0, 255),\n            y_label=\"jerk\",\n            min_val=0,\n        )\n        plots.append(plot)\n\n    # Body angle\n    if history.get(\"body_angles\"):\n        plot = create_metric_plot(\n            history[\"body_angles\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Body Angle (lean)\",\n            color=(128, 128, 255),\n            y_label=\"deg\",\n        )\n        plots.append(plot)\n\n    # Movement Economy\n    if history.get(\"movement_economy\"):\n        plot = create_metric_plot(\n            history[\"movement_economy\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Movement Economy (efficiency)\",\n            color=(0, 200, 100),\n            y_label=\"ratio\",\n            min_val=0,\n        )\n        plots.append(plot)\n\n    # Lock-offs (boolean visualized as 0/1)\n    if history.get(\"lock_offs\"):\n        plot = create_metric_plot(\n            history[\"lock_offs\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Lock-off Positions\",\n            color=(255, 100, 0),\n            y_label=\"active\",\n            min_val=0,\n            max_val=1,\n        )\n        plots.append(plot)\n\n    # Fatigue indicator (show in early plots for visibility)\n    # We'll calculate a simple rolling average of jerk to show fatigue trend\n\n    # Hand span\n    if history.get(\"hand_spans\"):\n        plot = create_metric_plot(\n            history[\"hand_spans\"],\n            current_frame,\n            plot_width,\n            plot_height,\n            title=\"Hand Span\",\n            color=(0, 128, 255),\n            y_label=\"span\",\n            min_val=0,\n        )\n        plots.append(plot)\n\n    # Stack plots vertically\n    if plots:\n        dashboard = np.vstack(plots)\n    else:\n        dashboard = np.zeros((100, plot_width, 3), dtype=np.uint8)\n\n    return dashboard\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#compose_frame_with_dashboard","title":"compose_frame_with_dashboard","text":"<p>Compose video frame side-by-side with metrics dashboard (no overlay).</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Input video frame</p> required <code>dashboard</code> <code>ndarray</code> <p>Metrics dashboard image</p> required <code>position</code> <code>str</code> <p>Where to place dashboard (\"right\" or \"left\")</p> <code>'right'</code> <code>spacing</code> <code>int</code> <p>Pixels of spacing between frame and dashboard</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Composite frame with video and dashboard side-by-side</p> Source code in <code>src/climb_sensei/metrics_viz.py</code> <pre><code>def compose_frame_with_dashboard(\n    frame: np.ndarray,\n    dashboard: np.ndarray,\n    position: str = \"right\",\n    spacing: int = 0,\n) -&gt; np.ndarray:\n    \"\"\"Compose video frame side-by-side with metrics dashboard (no overlay).\n\n    Args:\n        frame: Input video frame\n        dashboard: Metrics dashboard image\n        position: Where to place dashboard (\"right\" or \"left\")\n        spacing: Pixels of spacing between frame and dashboard\n\n    Returns:\n        Composite frame with video and dashboard side-by-side\n    \"\"\"\n    frame_h, frame_w = frame.shape[:2]\n    dash_h, dash_w = dashboard.shape[:2]\n\n    # Match dashboard height to frame height\n    if dash_h != frame_h:\n        # Scale dashboard to match frame height while maintaining aspect ratio\n        scale = frame_h / dash_h\n        new_w = int(dash_w * scale)\n        dashboard = cv2.resize(\n            dashboard, (new_w, frame_h), interpolation=cv2.INTER_LINEAR\n        )\n        dash_h, dash_w = dashboard.shape[:2]\n\n    # Create composite frame\n    total_width = frame_w + dash_w + spacing\n    composite = np.zeros((frame_h, total_width, 3), dtype=np.uint8)\n\n    if position == \"right\":\n        # Video on left, dashboard on right\n        composite[:, :frame_w] = frame\n        composite[:, frame_w + spacing :] = dashboard\n    else:  # left\n        # Dashboard on left, video on right\n        composite[:, :dash_w] = dashboard\n        composite[:, dash_w + spacing :] = frame\n\n    return composite\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#overlay_metrics_on_frame","title":"overlay_metrics_on_frame","text":"<p>Overlay metrics dashboard on video frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Input video frame (BGR)</p> required <code>dashboard</code> <code>ndarray</code> <p>Dashboard image from create_metrics_dashboard</p> required <code>position</code> <code>str</code> <p>Where to place dashboard (\"right\", \"left\", \"bottom\")</p> <code>'right'</code> <code>alpha</code> <code>float</code> <p>Opacity of dashboard (0.0 = transparent, 1.0 = opaque)</p> <code>0.9</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame with dashboard overlaid</p> Source code in <code>src/climb_sensei/metrics_viz.py</code> <pre><code>def overlay_metrics_on_frame(\n    frame: np.ndarray,\n    dashboard: np.ndarray,\n    position: str = \"right\",\n    alpha: float = 0.9,\n) -&gt; np.ndarray:\n    \"\"\"Overlay metrics dashboard on video frame.\n\n    Args:\n        frame: Input video frame (BGR)\n        dashboard: Dashboard image from create_metrics_dashboard\n        position: Where to place dashboard (\"right\", \"left\", \"bottom\")\n        alpha: Opacity of dashboard (0.0 = transparent, 1.0 = opaque)\n\n    Returns:\n        Frame with dashboard overlaid\n    \"\"\"\n    frame_h, frame_w = frame.shape[:2]\n    dash_h, dash_w = dashboard.shape[:2]\n\n    # Create output frame\n    output = frame.copy()\n\n    if position == \"right\":\n        # Place on right side\n        x_offset = frame_w - dash_w - 10\n        y_offset = 10\n    elif position == \"left\":\n        # Place on left side\n        x_offset = 10\n        y_offset = 10\n    elif position == \"bottom\":\n        # Place at bottom center\n        x_offset = (frame_w - dash_w) // 2\n        y_offset = frame_h - dash_h - 10\n    else:\n        x_offset = 10\n        y_offset = 10\n\n    # Ensure dashboard fits\n    if x_offset + dash_w &gt; frame_w:\n        x_offset = frame_w - dash_w\n    if y_offset + dash_h &gt; frame_h:\n        y_offset = frame_h - dash_h\n    if x_offset &lt; 0:\n        x_offset = 0\n    if y_offset &lt; 0:\n        y_offset = 0\n\n    # Clip dashboard if needed\n    dash_w = min(dash_w, frame_w - x_offset)\n    dash_h = min(dash_h, frame_h - y_offset)\n    dashboard = dashboard[:dash_h, :dash_w]\n\n    # Blend dashboard onto frame\n    roi = output[y_offset : y_offset + dash_h, x_offset : x_offset + dash_w]\n    blended = cv2.addWeighted(dashboard, alpha, roi, 1 - alpha, 0)\n    output[y_offset : y_offset + dash_h, x_offset : x_offset + dash_w] = blended\n\n    return output\n</code></pre> <p>options: show_source: true heading_level: 4</p>"},{"location":"api/#configuration","title":"Configuration","text":"<p>Configuration for pose visualization and analysis.</p> <p>This module defines application-wide configuration including: - Pose landmarks and connections for climbing analysis - Model configuration (confidence thresholds, etc.) - Metrics calculation parameters - Visualization styling (colors, dimensions, etc.)</p> <p>options: show_source: true heading_level: 3</p>"},{"location":"api/#climb_sensei.config.LandmarkIndex","title":"<code>LandmarkIndex</code>","text":"<p>MediaPipe Pose landmark indices.</p> <p>Centralized definition of landmark indices for consistency across modules.</p> Source code in <code>src/climb_sensei/config.py</code> <pre><code>class LandmarkIndex:\n    \"\"\"MediaPipe Pose landmark indices.\n\n    Centralized definition of landmark indices for consistency across modules.\n    \"\"\"\n\n    # Face/Head (0-10)\n    NOSE = 0\n    LEFT_EYE_INNER = 1\n    LEFT_EYE = 2\n    LEFT_EYE_OUTER = 3\n    RIGHT_EYE_INNER = 4\n    RIGHT_EYE = 5\n    RIGHT_EYE_OUTER = 6\n    LEFT_EAR = 7\n    RIGHT_EAR = 8\n    MOUTH_LEFT = 9\n    MOUTH_RIGHT = 10\n\n    # Upper Body\n    LEFT_SHOULDER = 11\n    RIGHT_SHOULDER = 12\n    LEFT_ELBOW = 13\n    RIGHT_ELBOW = 14\n    LEFT_WRIST = 15\n    RIGHT_WRIST = 16\n\n    # Hands\n    LEFT_PINKY = 17\n    RIGHT_PINKY = 18\n    LEFT_INDEX = 19\n    RIGHT_INDEX = 20\n    LEFT_THUMB = 21\n    RIGHT_THUMB = 22\n\n    # Lower Body\n    LEFT_HIP = 23\n    RIGHT_HIP = 24\n    LEFT_KNEE = 25\n    RIGHT_KNEE = 26\n    LEFT_ANKLE = 27\n    RIGHT_ANKLE = 28\n    LEFT_HEEL = 29\n    RIGHT_HEEL = 30\n    LEFT_FOOT_INDEX = 31\n    RIGHT_FOOT_INDEX = 32\n</code></pre>"},{"location":"api/#climb_sensei.config.MetricsConfig","title":"<code>MetricsConfig</code>  <code>dataclass</code>","text":"<p>Immutable metrics calculation configuration.</p> <p>Attributes:</p> Name Type Description <code>lock_off_threshold_degrees</code> <code>float</code> <p>Elbow angle threshold for lock-off detection</p> <code>rest_velocity_threshold</code> <code>float</code> <p>Max velocity for rest position detection</p> <code>rest_body_angle_threshold</code> <code>float</code> <p>Max body angle for rest position (degrees)</p> <code>efficient_economy_ratio</code> <code>float</code> <p>Threshold for efficient movement economy</p> <code>fatigue_window_size</code> <code>int</code> <p>Number of frames for fatigue analysis</p> <code>com_body_weight</code> <code>float</code> <p>Weight factor for center of mass calculation</p> Source code in <code>src/climb_sensei/config.py</code> <pre><code>@dataclass(frozen=True)\nclass MetricsConfig:\n    \"\"\"Immutable metrics calculation configuration.\n\n    Attributes:\n        lock_off_threshold_degrees: Elbow angle threshold for lock-off detection\n        rest_velocity_threshold: Max velocity for rest position detection\n        rest_body_angle_threshold: Max body angle for rest position (degrees)\n        efficient_economy_ratio: Threshold for efficient movement economy\n        fatigue_window_size: Number of frames for fatigue analysis\n        com_body_weight: Weight factor for center of mass calculation\n    \"\"\"\n\n    lock_off_threshold_degrees: float = 90.0\n    lock_off_velocity_threshold: float = 0.002\n    rest_velocity_threshold: float = 0.01\n    rest_body_angle_threshold: float = 15.0\n    efficient_economy_ratio: float = 0.8\n    fatigue_window_size: int = 90\n    com_body_weight: float = 1.0\n\n    # Keep class constants for backward compatibility\n    LOCK_OFF_THRESHOLD_DEGREES: float = 90\n    LOCK_OFF_VELOCITY_THRESHOLD: float = 0.002\n    REST_VELOCITY_THRESHOLD: float = 0.01\n    REST_BODY_ANGLE_THRESHOLD: float = 15\n    EFFICIENT_ECONOMY_RATIO: float = 0.8\n    FATIGUE_WINDOW_SIZE: int = 90\n    COM_BODY_WEIGHT: float = 1.0\n</code></pre>"},{"location":"api/#climb_sensei.config.PoseConfig","title":"<code>PoseConfig</code>  <code>dataclass</code>","text":"<p>Immutable pose detection and tracking configuration.</p> <p>Attributes:</p> Name Type Description <code>min_detection_confidence</code> <code>float</code> <p>Minimum confidence for pose detection (0.0-1.0)</p> <code>min_tracking_confidence</code> <code>float</code> <p>Minimum confidence for pose tracking (0.0-1.0)</p> <code>timestamp_increment_ms</code> <code>int</code> <p>Milliseconds per frame for temporal smoothing</p> Source code in <code>src/climb_sensei/config.py</code> <pre><code>@dataclass(frozen=True)\nclass PoseConfig:\n    \"\"\"Immutable pose detection and tracking configuration.\n\n    Attributes:\n        min_detection_confidence: Minimum confidence for pose detection (0.0-1.0)\n        min_tracking_confidence: Minimum confidence for pose tracking (0.0-1.0)\n        timestamp_increment_ms: Milliseconds per frame for temporal smoothing\n    \"\"\"\n\n    min_detection_confidence: float = 0.5\n    min_tracking_confidence: float = 0.5\n    timestamp_increment_ms: int = 33  # ~30fps\n\n    # Keep class constants for backward compatibility\n    DEFAULT_DETECTION_CONFIDENCE: float = 0.5\n    DEFAULT_TRACKING_CONFIDENCE: float = 0.5\n    TIMESTAMP_INCREMENT_MS: int = 33\n\n    def __post_init__(self):\n        \"\"\"Validate configuration values.\"\"\"\n        if not 0.0 &lt;= self.min_detection_confidence &lt;= 1.0:\n            raise ValueError(\"min_detection_confidence must be between 0.0 and 1.0\")\n        if not 0.0 &lt;= self.min_tracking_confidence &lt;= 1.0:\n            raise ValueError(\"min_tracking_confidence must be between 0.0 and 1.0\")\n</code></pre>"},{"location":"api/#climb_sensei.config.PoseConfig.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate configuration values.</p> Source code in <code>src/climb_sensei/config.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Validate configuration values.\"\"\"\n    if not 0.0 &lt;= self.min_detection_confidence &lt;= 1.0:\n        raise ValueError(\"min_detection_confidence must be between 0.0 and 1.0\")\n    if not 0.0 &lt;= self.min_tracking_confidence &lt;= 1.0:\n        raise ValueError(\"min_tracking_confidence must be between 0.0 and 1.0\")\n</code></pre>"},{"location":"api/#climb_sensei.config.VisualizationConfig","title":"<code>VisualizationConfig</code>","text":"<p>Visualization styling configuration.</p> Source code in <code>src/climb_sensei/config.py</code> <pre><code>class VisualizationConfig:\n    \"\"\"Visualization styling configuration.\"\"\"\n\n    # Body part colors (BGR format for OpenCV)\n    COLORS: Dict[str, Tuple[int, int, int]] = {\n        \"face\": (255, 255, 255),  # White\n        \"torso\": (0, 255, 255),  # Yellow\n        \"left_arm\": (0, 255, 0),  # Green\n        \"right_arm\": (0, 0, 255),  # Red\n        \"left_leg\": (255, 0, 255),  # Magenta\n        \"right_leg\": (255, 128, 0),  # Orange\n        \"default\": (200, 200, 200),  # Gray\n        \"connection\": (255, 255, 255),  # White\n    }\n\n    # Drawing dimensions\n    DEFAULT_LINE_THICKNESS = 3\n    DEFAULT_CIRCLE_RADIUS = 7\n    LANDMARK_BORDER_THICKNESS = 2\n\n    # Text styling\n    DEFAULT_FONT_SCALE = 3.0\n    DEFAULT_FONT_THICKNESS = 2\n\n    # Metrics overlay layout\n    METRICS_OVERLAY_PADDING = 15\n    METRICS_LINE_HEIGHT = 50\n    METRICS_OVERLAY_BG_ALPHA = 0.7\n\n    # Angle annotation\n    ANGLE_ANNOTATION_PADDING = 5\n\n    # Plot settings for metrics dashboard\n    PLOT_WIDTH = 500\n    PLOT_HEIGHT = 150\n    PLOT_BACKGROUND_COLOR = (40, 40, 40)  # BGR\n    PLOT_MARGIN_LEFT = 70\n    PLOT_MARGIN_RIGHT = 15\n    PLOT_MARGIN_TOP = 40\n    PLOT_MARGIN_BOTTOM = 25\n\n    # Plot text styling\n    PLOT_TITLE_FONT_SCALE = 0.8\n    PLOT_TITLE_THICKNESS = 2\n    PLOT_TITLE_COLOR = (200, 200, 200)  # BGR\n    PLOT_LABEL_FONT_SCALE = 0.5\n    PLOT_LABEL_THICKNESS = 2\n    PLOT_LABEL_COLOR = (150, 150, 150)  # BGR\n\n    # Plot elements\n    PLOT_GRID_COLOR = (60, 60, 60)  # BGR\n    PLOT_LINE_THICKNESS = 2\n    PLOT_CURRENT_MARKER_INNER_COLOR = (255, 255, 255)  # BGR - white\n    PLOT_CURRENT_MARKER_INNER_RADIUS = 4\n    PLOT_CURRENT_MARKER_OUTER_RADIUS = 6\n    PLOT_CURRENT_MARKER_OUTER_THICKNESS = 2\n    PLOT_CURRENT_LINE_COLOR = (100, 100, 100)  # BGR - gray vertical line\n</code></pre>"},{"location":"api/#climb_sensei.config.get_landmark_name","title":"<code>get_landmark_name(index)</code>","text":"<p>Get the human-readable name for a landmark index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Landmark index (0-32).</p> required <p>Returns:</p> Type Description <code>str</code> <p>Human-readable landmark name.</p> Source code in <code>src/climb_sensei/config.py</code> <pre><code>def get_landmark_name(index: int) -&gt; str:\n    \"\"\"Get the human-readable name for a landmark index.\n\n    Args:\n        index: Landmark index (0-32).\n\n    Returns:\n        Human-readable landmark name.\n    \"\"\"\n    landmark_names = {\n        0: \"nose\",\n        1: \"left_eye_inner\",\n        2: \"left_eye\",\n        3: \"left_eye_outer\",\n        4: \"right_eye_inner\",\n        5: \"right_eye\",\n        6: \"right_eye_outer\",\n        7: \"left_ear\",\n        8: \"right_ear\",\n        9: \"mouth_left\",\n        10: \"mouth_right\",\n        11: \"left_shoulder\",\n        12: \"right_shoulder\",\n        13: \"left_elbow\",\n        14: \"right_elbow\",\n        15: \"left_wrist\",\n        16: \"right_wrist\",\n        17: \"left_pinky\",\n        18: \"right_pinky\",\n        19: \"left_index\",\n        20: \"right_index\",\n        21: \"left_thumb\",\n        22: \"right_thumb\",\n        23: \"left_hip\",\n        24: \"right_hip\",\n        25: \"left_knee\",\n        26: \"right_knee\",\n        27: \"left_ankle\",\n        28: \"right_ankle\",\n        29: \"left_heel\",\n        30: \"right_heel\",\n        31: \"left_foot_index\",\n        32: \"right_foot_index\",\n    }\n    return landmark_names.get(index, f\"unknown_{index}\")\n</code></pre>"},{"location":"architecture/","title":"Architecture","text":"<p>climb-sensei follows strict Separation of Concerns principles for maintainability and testability.</p>"},{"location":"architecture/#design-principles","title":"Design Principles","text":"<ol> <li>Single Responsibility: Each module has one clear purpose</li> <li>Stateless Functions: Pure functions in biomechanics module</li> <li>Dependency Injection: Context managers for resource management</li> <li>Type Safety: Comprehensive type hints throughout</li> <li>Test Coverage: 82% coverage with 164 unit tests</li> </ol>"},{"location":"architecture/#module-overview","title":"Module Overview","text":""},{"location":"architecture/#configpy","title":"config.py","text":"<p>Purpose: Application-wide configuration and constants</p> <ul> <li>Defines MediaPipe confidence thresholds</li> <li>Video encoding parameters</li> <li>Metric calculation constants</li> <li>Color schemes and visualization settings</li> </ul> <p>Key Exports: Configuration dataclasses and constants</p>"},{"location":"architecture/#video_iopy","title":"video_io.py","text":"<p>Purpose: Video input/output operations</p> <p>Responsibilities:</p> <ul> <li>Read video files with <code>VideoReader</code></li> <li>Write video files with <code>VideoWriter</code></li> <li>Expose frame properties (fps, dimensions)</li> <li>Handle codec and format conversion</li> </ul> <p>Key Classes:</p> <ul> <li><code>VideoReader</code>: Context manager for reading videos</li> <li><code>VideoWriter</code>: Context manager for writing videos</li> </ul> <p>No Business Logic: Pure I/O operations only</p>"},{"location":"architecture/#pose_enginepy","title":"pose_engine.py","text":"<p>Purpose: MediaPipe pose detection wrapper</p> <p>Responsibilities:</p> <ul> <li>Initialize MediaPipe Pose model</li> <li>Process frames for pose detection</li> <li>Extract normalized landmark coordinates</li> <li>Manage model lifecycle</li> </ul> <p>Key Class: <code>PoseEngine</code></p> <p>Single Responsibility: Wraps MediaPipe, nothing else</p>"},{"location":"architecture/#biomechanicspy","title":"biomechanics.py","text":"<p>Purpose: Pure mathematical calculations</p> <p>Characteristics:</p> <ul> <li>All functions are stateless</li> <li>No side effects</li> <li>Fully testable with simple inputs</li> <li>No dependencies on other modules</li> </ul> <p>Functions:</p> <ul> <li><code>calculate_joint_angle()</code>: 3-point angle calculation</li> <li><code>calculate_reach_distance()</code>: Euclidean distance</li> <li><code>calculate_center_of_mass()</code>: Weighted average position</li> <li><code>calculate_limb_angles()</code>: All 8 joint angles</li> <li><code>calculate_total_distance_traveled()</code>: Path length</li> </ul> <p>Philosophy: If it's math, it goes here</p>"},{"location":"architecture/#metricspy","title":"metrics.py","text":"<p>Purpose: Temporal analysis and stateful tracking</p> <p>Key Class: <code>ClimbingAnalyzer</code></p> <p>Responsibilities:</p> <ul> <li>Track metrics over time (stateful)</li> <li>Calculate moving averages</li> <li>Detect patterns (lock-offs, rest positions)</li> <li>Compute summary statistics</li> <li>Maintain frame history</li> </ul> <p>Design Pattern: Object-oriented state management</p> <p>Dependencies: Uses <code>biomechanics.py</code> for calculations</p>"},{"location":"architecture/#metrics_vizpy","title":"metrics_viz.py","text":"<p>Purpose: Metrics dashboard visualization</p> <p>Responsibilities:</p> <ul> <li>Create time-series plots</li> <li>Generate dashboard layouts</li> <li>Compose side-by-side visualizations</li> <li>Format metric displays</li> </ul> <p>Functions:</p> <ul> <li><code>create_metrics_dashboard()</code>: Generate plots</li> <li><code>compose_frame_with_dashboard()</code>: Side-by-side layout</li> </ul> <p>Presentation Layer: Purely visual output</p>"},{"location":"architecture/#vizpy","title":"viz.py","text":"<p>Purpose: Pose rendering and annotation</p> <p>Responsibilities:</p> <ul> <li>Draw pose landmarks on frames</li> <li>Render skeleton connections</li> <li>Add text overlays</li> <li>Dashboard overlay composition</li> </ul> <p>Functions:</p> <ul> <li><code>draw_pose_landmarks()</code>: Render pose visualization</li> <li><code>overlay_metrics_dashboard()</code>: Alpha-blend dashboard</li> </ul> <p>Presentation Layer: Visual pose feedback</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<pre><code>Input Video\n    \u2193\nVideoReader \u2192 Frame\n    \u2193\nPoseEngine \u2192 Landmarks (33 points)\n    \u2193\nbiomechanics.py \u2192 Joint Angles, Distances\n    \u2193\nClimbingAnalyzer \u2192 Metrics Dictionary\n    \u2193\n    \u251c\u2192 metrics_viz.py \u2192 Dashboard\n    \u251c\u2192 viz.py \u2192 Annotated Frame\n    \u2514\u2192 Summary Statistics\n    \u2193\nVideoWriter \u2192 Output Video\n</code></pre>"},{"location":"architecture/#testing-strategy","title":"Testing Strategy","text":""},{"location":"architecture/#unit-tests-164-tests-82-coverage","title":"Unit Tests (164 tests, 82% coverage)","text":"<p>biomechanics.py: Pure function testing</p> <ul> <li>Input/output validation</li> <li>Edge cases (zero distances, collinear points)</li> <li>Mathematical correctness</li> </ul> <p>metrics.py: State management testing</p> <ul> <li>Moving average windows</li> <li>Pattern detection accuracy</li> <li>Summary calculation correctness</li> </ul> <p>video_io.py: I/O testing</p> <ul> <li>File handling</li> <li>Property exposure</li> <li>Codec compatibility</li> </ul> <p>pose_engine.py: Integration testing</p> <ul> <li>MediaPipe initialization</li> <li>Landmark extraction</li> <li>Resource cleanup</li> </ul>"},{"location":"architecture/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_biomechanics.py       # Pure functions\n\u251c\u2500\u2500 test_metrics.py            # ClimbingAnalyzer\n\u251c\u2500\u2500 test_video_io.py          # Video I/O\n\u251c\u2500\u2500 test_pose_engine.py       # Pose detection\n\u251c\u2500\u2500 test_viz.py               # Visualization\n\u2514\u2500\u2500 test_patterns.py          # Design patterns\n</code></pre>"},{"location":"architecture/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/#facade-pattern","title":"Facade Pattern","text":"<p>Location: <code>__init__.py</code></p> <p>Simplifies the API by exposing only essential classes:</p> <pre><code>from climb_sensei import PoseEngine, ClimbingAnalyzer\n# vs\nfrom climb_sensei.pose_engine import PoseEngine\nfrom climb_sensei.metrics import ClimbingAnalyzer\n</code></pre>"},{"location":"architecture/#builder-pattern","title":"Builder Pattern","text":"<p>Location: <code>metrics.py</code></p> <p><code>ClimbingAnalyzer</code> builds complex state over time:</p> <pre><code>analyzer = ClimbingAnalyzer(window_size=30, fps=30)\nfor landmarks in frames:\n    metrics = analyzer.analyze_frame(landmarks)  # Builds internal state\nsummary = analyzer.get_summary()  # Final product\n</code></pre>"},{"location":"architecture/#context-manager-pattern","title":"Context Manager Pattern","text":"<p>Location: <code>video_io.py</code>, <code>pose_engine.py</code></p> <p>Automatic resource management:</p> <pre><code>with VideoReader('input.mp4') as video:\n    # Resources automatically cleaned up\n</code></pre>"},{"location":"architecture/#repository-pattern","title":"Repository Pattern","text":"<p>Location: <code>metrics.py</code></p> <p><code>ClimbingAnalyzer</code> stores and retrieves historical data:</p> <pre><code>history = analyzer.get_history()  # Retrieve all stored data\nsummary = analyzer.get_summary()  # Aggregate view\n</code></pre>"},{"location":"architecture/#extensibility","title":"Extensibility","text":""},{"location":"architecture/#adding-new-metrics","title":"Adding New Metrics","text":"<ol> <li>Pure Calculation: Add function to <code>biomechanics.py</code></li> <li>Temporal Tracking: Extend <code>ClimbingAnalyzer</code> in <code>metrics.py</code></li> <li>Visualization: Add plot to <code>metrics_viz.py</code></li> <li>Tests: Add test coverage</li> </ol> <p>Example:</p> <pre><code># 1. biomechanics.py\ndef calculate_leg_extension(landmarks: List[Tuple[float, float]]) -&gt; float:\n    \"\"\"Pure calculation\"\"\"\n    return distance\n\n# 2. metrics.py\nclass ClimbingAnalyzer:\n    def analyze_frame(self, landmarks):\n        leg_extension = calculate_leg_extension(landmarks)\n        self._leg_extensions.append(leg_extension)\n        return {'leg_extension': leg_extension, ...}\n\n# 3. metrics_viz.py\ndef create_metrics_dashboard(history, ...):\n    ax.plot(history['leg_extensions'])\n</code></pre>"},{"location":"architecture/#adding-new-visualization","title":"Adding New Visualization","text":"<p>Create new function in <code>viz.py</code> or <code>metrics_viz.py</code>:</p> <pre><code>def draw_custom_overlay(frame, data):\n    # Custom visualization logic\n    return annotated_frame\n</code></pre>"},{"location":"architecture/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>MediaPipe: GPU acceleration when available</li> <li>NumPy: Vectorized operations for biomechanics</li> <li>OpenCV: Hardware video decoding</li> <li>Moving Averages: O(1) amortized with deque</li> </ul>"},{"location":"architecture/#future-architecture-plans","title":"Future Architecture Plans","text":"<ul> <li> Plugin system for custom metrics</li> <li> Async video processing pipeline</li> <li> Real-time streaming support</li> <li> Multi-person tracking</li> <li> 3D pose reconstruction</li> </ul>"},{"location":"development/","title":"Development Guide","text":""},{"location":"development/#setup","title":"Setup","text":""},{"location":"development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or 3.13</li> <li>uv package manager</li> <li>Git</li> </ul>"},{"location":"development/#clone-and-install","title":"Clone and Install","text":"<pre><code># Clone repository\ngit clone https://github.com/jpsferreira/climb-sensei.git\ncd climb-sensei\n\n# Install with dev dependencies\nuv sync --extra dev\n\n# Install pre-commit hooks\nmake pre-commit-install\n</code></pre>"},{"location":"development/#development-tools","title":"Development Tools","text":""},{"location":"development/#makefile-targets","title":"Makefile Targets","text":"<p>The project includes a comprehensive Makefile with 19 targets:</p> <pre><code># Install dependencies\nmake install          # Production dependencies only\nmake install-dev      # Include dev dependencies\n\n# Code Quality\nmake check           # Run all checks (ruff + black)\nmake lint            # Run ruff linter\nmake lint-fix        # Auto-fix linting issues\nmake format          # Format with black\nmake format-check    # Check formatting without changes\n\n# Testing\nmake test            # Run all tests\nmake test-fast       # Run without coverage\nmake coverage        # Generate coverage report\nmake test-watch      # Run tests in watch mode\n\n# Pre-commit\nmake pre-commit-install    # Install git hooks\nmake pre-commit           # Run all hooks manually\n\n# Maintenance\nmake clean           # Remove build artifacts\nmake update          # Update dependencies\nmake lock            # Update uv.lock\n\n# Build\nmake build           # Build distribution packages\nmake qa              # Quality assurance (check + test)\n\n# Run\nmake run             # Run the demo\nmake analyze         # Analyze a video (VIDEO=path/to/video.mp4)\n</code></pre>"},{"location":"development/#using-makefile","title":"Using Makefile","text":"<pre><code># Quick quality check\nmake qa\n\n# Full development cycle\nmake install-dev\nmake pre-commit-install\nmake test\nmake check\n\n# Before committing\nmake qa\n</code></pre>"},{"location":"development/#code-quality","title":"Code Quality","text":""},{"location":"development/#linting-with-ruff","title":"Linting with Ruff","text":"<pre><code># Check for issues\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n\n# Or use make\nmake lint-fix\n</code></pre>"},{"location":"development/#formatting-with-black","title":"Formatting with Black","text":"<pre><code># Check formatting\nuv run black --check .\n\n# Format code\nuv run black .\n\n# Or use make\nmake format\n</code></pre>"},{"location":"development/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Automatically run checks before each commit:</p> <pre><code># Install hooks\nuv run pre-commit install\n\n# Run manually\nuv run pre-commit run --all-files\n\n# Or use make\nmake pre-commit\n</code></pre> <p>Configured hooks:</p> <ul> <li>ruff: Linting and auto-fixes</li> <li>black: Code formatting</li> <li>prettier: YAML/Markdown formatting</li> <li>yaml-check: YAML syntax validation</li> <li>toml-check: TOML syntax validation</li> <li>trailing-whitespace: Remove trailing spaces</li> <li>end-of-file-fixer: Ensure newline at EOF</li> </ul>"},{"location":"development/#testing","title":"Testing","text":""},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># All tests with coverage\nuv run pytest tests/ --cov\n\n# Verbose output\nuv run pytest tests/ -v\n\n# Specific test file\nuv run pytest tests/test_biomechanics.py\n\n# Or use make\nmake test\n</code></pre>"},{"location":"development/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 test_biomechanics.py      # Pure function tests\n\u251c\u2500\u2500 test_metrics.py           # ClimbingAnalyzer tests\n\u251c\u2500\u2500 test_video_io.py          # Video I/O tests\n\u251c\u2500\u2500 test_pose_engine.py       # Pose detection tests\n\u251c\u2500\u2500 test_viz.py               # Visualization tests\n\u2514\u2500\u2500 test_patterns.py          # Design pattern tests\n</code></pre>"},{"location":"development/#coverage-reports","title":"Coverage Reports","text":"<pre><code># Terminal coverage report\nmake coverage\n\n# HTML coverage report\nuv run pytest tests/ --cov --cov-report=html\nopen htmlcov/index.html\n</code></pre> <p>Current coverage: 82% (164 tests)</p>"},{"location":"development/#writing-tests","title":"Writing Tests","text":"<p>Follow existing patterns:</p> <pre><code>import pytest\nfrom climb_sensei.biomechanics import calculate_joint_angle\n\ndef test_joint_angle_calculation():\n    \"\"\"Test basic angle calculation.\"\"\"\n    point_a = (0, 0)\n    point_b = (0, 1)\n    point_c = (1, 1)\n\n    angle = calculate_joint_angle(point_a, point_b, point_c)\n    assert abs(angle - 90.0) &lt; 0.01\n\ndef test_joint_angle_edge_cases():\n    \"\"\"Test edge cases.\"\"\"\n    # Collinear points\n    angle = calculate_joint_angle((0,0), (1,1), (2,2))\n    assert abs(angle - 180.0) &lt; 0.01\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":""},{"location":"development/#building-docs","title":"Building Docs","text":"<pre><code># Install mkdocs (included in dev dependencies)\nuv sync --extra dev\n\n# Serve docs locally\nuv run mkdocs serve\n\n# Build static site\nuv run mkdocs build\n\n# Deploy to GitHub Pages\nuv run mkdocs gh-deploy\n</code></pre>"},{"location":"development/#writing-documentation","title":"Writing Documentation","text":"<p>Documentation uses MkDocs with Material theme.</p> <p>File locations:</p> <ul> <li><code>docs/index.md</code>: Homepage</li> <li><code>docs/installation.md</code>: Installation guide</li> <li><code>docs/usage.md</code>: Usage examples</li> <li><code>docs/api.md</code>: API reference</li> <li><code>docs/metrics.md</code>: Metrics documentation</li> <li><code>docs/architecture.md</code>: Architecture overview</li> <li><code>docs/development.md</code>: This file</li> </ul> <p>Editing tips:</p> <pre><code># Use admonitions for notes\n\n!!! note\nThis is a note\n\n!!! warning\nThis is a warning\n\n# Code blocks with syntax highlighting\n\n```python\nfrom climb_sensei import PoseEngine\n```\n</code></pre>"},{"location":"development/#math-equations-with-katex","title":"Math equations with KaTeX","text":"<p>Inline: \\(x^2 + y^2 = z^2\\) Block: $\\(\\frac{vertical\\_progress}{total\\_distance}\\)$</p> <pre><code>## CI/CD\n\n### GitHub Actions Workflows\n\nFour automated workflows:\n\n#### 1. CI (`ci.yaml`)\n- **Triggers**: Push to main, pull requests\n- **Jobs**:\n  - Quality: Ruff + Black checks\n  - Test: Python 3.12 &amp; 3.13\n  - Coverage: Upload to Codecov\n\n#### 2. Pre-commit (`pre-commit.yaml`)\n- **Triggers**: Push, pull requests\n- **Action**: Run all pre-commit hooks\n\n#### 3. Release (`release.yaml`)\n- **Triggers**: GitHub release published\n- **Action**: Build and publish to PyPI\n\n#### 4. Codecov Validation (`validate-codecov.yaml`)\n- **Triggers**: Changes to codecov.yaml\n- **Action**: Validate configuration\n\n### Local CI Simulation\n\n```bash\n# Run quality checks\nmake check\n\n# Run tests (both Python versions locally)\nuv run pytest tests/\n\n# Run pre-commit hooks\nmake pre-commit\n</code></pre>"},{"location":"development/#release-process","title":"Release Process","text":"<ol> <li>Update Version</li> </ol> <pre><code># Update version in pyproject.toml\nversion = \"0.2.0\"\n</code></pre> <ol> <li>Update Changelog</li> </ol> <pre><code># Add release notes\ngit commit -m \"Release v0.2.0\"\n</code></pre> <ol> <li>Create Git Tag</li> </ol> <pre><code>git tag v0.2.0\ngit push origin v0.2.0\n</code></pre> <ol> <li> <p>Create GitHub Release</p> </li> <li> <p>Go to GitHub Releases</p> </li> <li>Create new release from tag</li> <li>Add release notes</li> <li> <p>Publish release</p> </li> <li> <p>Automatic PyPI Upload</p> </li> <li>GitHub Actions automatically builds and publishes</li> <li>Uses trusted publishing (no API key needed)</li> </ol>"},{"location":"development/#code-style-guidelines","title":"Code Style Guidelines","text":""},{"location":"development/#type-hints","title":"Type Hints","text":"<p>Always use type hints:</p> <pre><code>def calculate_velocity(\n    current_pos: Tuple[float, float],\n    previous_pos: Tuple[float, float],\n    fps: int\n) -&gt; float:\n    \"\"\"Calculate velocity between positions.\"\"\"\n    ...\n</code></pre>"},{"location":"development/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings:</p> <pre><code>def analyze_frame(self, landmarks: List[Tuple[float, float]]) -&gt; Dict[str, Any]:\n    \"\"\"Analyze a single frame of pose landmarks.\n\n    Args:\n        landmarks: List of (x, y) coordinate tuples for 33 pose landmarks.\n\n    Returns:\n        Dictionary containing all computed metrics for this frame.\n\n    Raises:\n        ValueError: If landmarks list is invalid.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"development/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Functions/Variables: <code>snake_case</code></li> <li>Classes: <code>PascalCase</code></li> <li>Constants: <code>UPPER_CASE</code></li> <li>Private: <code>_leading_underscore</code></li> </ul>"},{"location":"development/#code-organization","title":"Code Organization","text":"<ol> <li>Imports (standard \u2192 third-party \u2192 local)</li> <li>Constants</li> <li>Classes/Functions</li> <li>Main block (if script)</li> </ol>"},{"location":"development/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/#common-issues","title":"Common Issues","text":"<p>Issue: Pre-commit hooks fail with \"command not found\"</p> <pre><code># Solution: Reinstall dev dependencies\nuv sync --extra dev\nmake pre-commit-install\n</code></pre> <p>Issue: Tests fail with import errors</p> <pre><code># Solution: Install package in editable mode\nuv sync --extra dev\n</code></pre> <p>Issue: Coverage report shows missing lines</p> <pre><code># Solution: Check if code is actually executed\nuv run pytest tests/ --cov --cov-report=term-missing\n</code></pre>"},{"location":"development/#contributing","title":"Contributing","text":"<ol> <li>Fork the repository</li> <li>Create feature branch: <code>git checkout -b feature/amazing-feature</code></li> <li>Make changes and add tests</li> <li>Run quality checks: <code>make qa</code></li> <li>Commit changes: <code>git commit -m \"Add amazing feature\"</code></li> <li>Push to branch: <code>git push origin feature/amazing-feature</code></li> <li>Open pull request</li> </ol>"},{"location":"development/#pull-request-checklist","title":"Pull Request Checklist","text":"<ul> <li> Code follows style guidelines (ruff + black)</li> <li> Added tests for new functionality</li> <li> All tests pass (<code>make test</code>)</li> <li> Documentation updated (if needed)</li> <li> Pre-commit hooks pass</li> <li> Coverage maintained or improved</li> </ul>"},{"location":"development/#resources","title":"Resources","text":"<ul> <li>uv Documentation</li> <li>MediaPipe Pose</li> <li>MkDocs Material</li> <li>Ruff</li> <li>pytest</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#using-uv-recommended","title":"Using uv (Recommended)","text":"<p>This project uses <code>uv</code> for fast, reliable package management:</p> <pre><code># Install uv (if not already installed)\npip install uv\n\n# Install the package\nuv sync\n\n# Or install with development dependencies\nuv sync --extra dev\n</code></pre>"},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code>pip install climb-sensei\n</code></pre>"},{"location":"installation/#from-source","title":"From Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/jpsferreira/climb-sensei.git\ncd climb-sensei\n\n# Install with uv\nuv sync\n\n# Or with pip\npip install -e .\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>For development, install with all extras:</p> <pre><code># Using uv\nuv sync --extra dev\n\n# Or using pip\npip install -e \".[dev]\"\n</code></pre> <p>This includes:</p> <ul> <li>pytest &amp; pytest-cov for testing</li> <li>ruff for linting</li> <li>black for code formatting</li> <li>pre-commit for git hooks</li> <li>mkdocs-material for documentation</li> </ul>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Run the demo\nuv run python -m climb_sensei\n\n# Or if installed with pip\npython -m climb_sensei\n</code></pre>"},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12 or higher (tested on 3.12 and 3.13)</li> <li>macOS, Linux, or Windows</li> <li>Webcam or video files for analysis</li> </ul>"},{"location":"installation/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>mediapipe &gt;= 0.10.30: Pose estimation</li> <li>opencv-python &gt;= 4.8.0: Video I/O and visualization</li> <li>numpy &gt;= 1.24.0: Numerical computations</li> <li>tqdm &gt;= 4.66.0: Progress bars</li> </ul>"},{"location":"installation/#development-dependencies","title":"Development Dependencies","text":"<ul> <li>pytest &gt;= 9.0.0: Testing framework</li> <li>pytest-cov &gt;= 7.0.0: Coverage reporting</li> <li>black &gt;= 24.0.0: Code formatting</li> <li>ruff &gt;= 0.9.0: Linting</li> <li>pre-commit &gt;= 4.0.0: Git hooks</li> <li>mkdocs-material &gt;= 9.0.0: Documentation</li> </ul>"},{"location":"metrics/","title":"Metrics Reference","text":"<p>Complete documentation of all 25+ climbing metrics available in climb-sensei.</p>"},{"location":"metrics/#core-movement-metrics","title":"Core Movement Metrics","text":""},{"location":"metrics/#hip-height","title":"Hip Height","text":"<p>Key: <code>hip_height</code> Type: <code>float</code> Units: Normalized coordinates (0.0 - 1.0)</p> <p>Current vertical position of the hips. In normalized MediaPipe coordinates where 0.0 is top of frame and 1.0 is bottom.</p> <p>Interpretation:</p> <ul> <li>Lower values = higher position in frame</li> <li>Decreasing over time = climbing upward</li> <li>Used as the primary vertical position indicator</li> </ul>"},{"location":"metrics/#center-of-mass-velocity","title":"Center of Mass Velocity","text":"<p>Key: <code>com_velocity</code> Type: <code>float</code> Units: Normalized units per second</p> <p>Speed of movement calculated from center of mass displacement over time.</p> <p>Interpretation:</p> <ul> <li>Higher values = faster movement</li> <li>Typical climbing: 0.01 - 0.1</li> <li>Very fast moves: &gt; 0.15</li> <li>Near stationary: &lt; 0.005</li> </ul>"},{"location":"metrics/#center-of-mass-sway","title":"Center of Mass Sway","text":"<p>Key: <code>com_sway</code> Type: <code>float</code> Units: Normalized units</p> <p>Lateral instability measure - standard deviation of horizontal position over recent frames.</p> <p>Interpretation:</p> <ul> <li>Lower values = more stable</li> <li>Excellent stability: &lt; 0.01</li> <li>Good stability: 0.01 - 0.02</li> <li>Poor stability: &gt; 0.03</li> <li>Indicates control and technique quality</li> </ul>"},{"location":"metrics/#jerk","title":"Jerk","text":"<p>Key: <code>jerk</code> Type: <code>float</code> Units: Normalized units per second\u00b2</p> <p>Rate of change of acceleration - measures movement smoothness.</p> <p>Interpretation:</p> <ul> <li>Lower values = smoother movement</li> <li>Smooth climbing: &lt; 0.001</li> <li>Jerky movement: &gt; 0.005</li> <li>Indicates fatigue or poor technique when high</li> </ul>"},{"location":"metrics/#body-angle","title":"Body Angle","text":"<p>Key: <code>body_angle</code> Type: <code>float</code> Units: Degrees (0\u00b0 - 90\u00b0)</p> <p>Lean angle from vertical, measured from hip-shoulder axis.</p> <p>Calculation: <code>arctan(abs(dx) / abs(dy))</code> where dx is horizontal distance and dy is vertical distance between shoulders and hips.</p> <p>Interpretation:</p> <ul> <li>0\u00b0 = Perfectly vertical (straight up)</li> <li>45\u00b0 = 45-degree lean</li> <li>90\u00b0 = Horizontal (laying out)</li> <li>Typical rest position: 5-15\u00b0</li> <li>Steep overhang climbing: 30-60\u00b0</li> </ul>"},{"location":"metrics/#hand-span","title":"Hand Span","text":"<p>Key: <code>hand_span</code> Type: <code>float</code> Units: Normalized units</p> <p>Distance between left and right wrists.</p> <p>Interpretation:</p> <ul> <li>Larger values = wider reach</li> <li>Changing rapidly = dynamic movement</li> <li>Small values = hands close together (mantling, jamming)</li> </ul>"},{"location":"metrics/#foot-span","title":"Foot Span","text":"<p>Key: <code>foot_span</code> Type: <code>float</code> Units: Normalized units</p> <p>Distance between left and right ankles.</p> <p>Interpretation:</p> <ul> <li>Larger values = wider stance</li> <li>Very small values = feet together (stemming, crack climbing)</li> </ul>"},{"location":"metrics/#vertical-progress","title":"Vertical Progress","text":"<p>Key: <code>vertical_progress</code> Type: <code>float</code> Units: Normalized units (cumulative)</p> <p>Total vertical distance climbed from starting position.</p> <p>Interpretation:</p> <ul> <li>Cumulative metric (increases over time)</li> <li>Measures total height gained</li> <li>Typical boulder problem: 0.3 - 0.6</li> <li>Full rope length: 2.0 - 3.0</li> </ul>"},{"location":"metrics/#efficiency-technique-metrics","title":"Efficiency &amp; Technique Metrics","text":""},{"location":"metrics/#movement-economy","title":"Movement Economy","text":"<p>Key: <code>movement_economy</code> Type: <code>float</code> Units: Ratio (0.0 - 1.0)</p> <p>Efficiency calculated as vertical progress divided by total distance traveled.</p> <p>Calculation: <code>vertical_progress / total_distance_traveled</code></p> <p>Interpretation:</p> <ul> <li>1.0 = Perfect efficiency (straight up)</li> <li>0.7 - 0.9 = Excellent efficiency</li> <li>0.5 - 0.7 = Good efficiency</li> <li>&lt; 0.5 = Poor efficiency (too much lateral movement)</li> </ul>"},{"location":"metrics/#lock-off-detection","title":"Lock-off Detection","text":"<p>Keys: <code>is_lock_off</code>, <code>left_lock_off</code>, <code>right_lock_off</code> Type: <code>bool</code> Units: Boolean</p> <p>Detects static bent-arm positions indicating lock-off holds.</p> <p>Detection Criteria:</p> <ul> <li>Elbow angle &lt; 110\u00b0 (bent arm)</li> <li>Low velocity (&lt; threshold)</li> <li>Sustained for multiple frames</li> </ul> <p>Interpretation:</p> <ul> <li><code>True</code> = Currently in lock-off</li> <li><code>left_lock_off</code> / <code>right_lock_off</code> = Per-arm detection</li> <li>High lock-off percentage indicates strength-intensive climbing</li> </ul>"},{"location":"metrics/#rest-position-detection","title":"Rest Position Detection","text":"<p>Key: <code>is_rest_position</code> Type: <code>bool</code> Units: Boolean</p> <p>Identifies low-stress vertical positions where climber can recover.</p> <p>Detection Criteria:</p> <ul> <li>Body angle &lt; 20\u00b0 (nearly vertical)</li> <li>Low velocity (near stationary)</li> </ul> <p>Interpretation:</p> <ul> <li><code>True</code> = Currently resting</li> <li>High rest percentage = good route reading</li> <li>Low rest percentage on hard routes = may indicate pumped climbing</li> </ul>"},{"location":"metrics/#joint-angles","title":"Joint Angles","text":"<p>All joint angles are measured in degrees using the three-point angle calculation.</p>"},{"location":"metrics/#elbow-angles","title":"Elbow Angles","text":"<p>Keys: <code>left_elbow</code>, <code>right_elbow</code> Type: <code>float</code> Units: Degrees (0\u00b0 - 180\u00b0)</p> <p>Angle formed by shoulder-elbow-wrist.</p> <p>Interpretation:</p> <ul> <li>180\u00b0 = Fully extended (straight arm)</li> <li>90\u00b0 = 90-degree bend</li> <li>&lt; 110\u00b0 = Lock-off position</li> <li>Typical climbing: 120\u00b0 - 160\u00b0</li> </ul>"},{"location":"metrics/#shoulder-angles","title":"Shoulder Angles","text":"<p>Keys: <code>left_shoulder</code>, <code>right_shoulder</code> Type: <code>float</code> Units: Degrees (0\u00b0 - 180\u00b0)</p> <p>Angle formed by hip-shoulder-elbow.</p> <p>Interpretation:</p> <ul> <li>90\u00b0 = Arm perpendicular to body</li> <li> <p>90\u00b0 = Arm raised above shoulder</p> </li> <li>&lt; 90\u00b0 = Arm below shoulder</li> <li>High angles (&gt;120\u00b0) = reaching overhead</li> </ul>"},{"location":"metrics/#knee-angles","title":"Knee Angles","text":"<p>Keys: <code>left_knee</code>, <code>right_knee</code> Type: <code>float</code> Units: Degrees (0\u00b0 - 180\u00b0)</p> <p>Angle formed by hip-knee-ankle.</p> <p>Interpretation:</p> <ul> <li>180\u00b0 = Fully extended leg</li> <li>90\u00b0 = Deep squat</li> <li>Typical climbing: 100\u00b0 - 170\u00b0</li> <li>&lt; 100\u00b0 = High step or knee bar</li> </ul>"},{"location":"metrics/#hip-angles","title":"Hip Angles","text":"<p>Keys: <code>left_hip</code>, <code>right_hip</code> Type: <code>float</code> Units: Degrees (0\u00b0 - 180\u00b0)</p> <p>Angle formed by shoulder-hip-knee.</p> <p>Interpretation:</p> <ul> <li>180\u00b0 = Fully extended body</li> <li>90\u00b0 = Bent at waist</li> <li>Typical climbing: 140\u00b0 - 170\u00b0</li> <li>Low angles indicate hip flexibility moves</li> </ul>"},{"location":"metrics/#summary-statistics","title":"Summary Statistics","text":"<p>Available via <code>analyzer.get_summary()</code>:</p>"},{"location":"metrics/#velocity-statistics","title":"Velocity Statistics","text":"<ul> <li><code>avg_velocity</code>: Mean velocity over entire climb</li> <li><code>max_velocity</code>: Peak velocity reached</li> <li><code>min_velocity</code>: Minimum velocity (excluding stops)</li> </ul>"},{"location":"metrics/#progress-metrics","title":"Progress Metrics","text":"<ul> <li><code>total_vertical_progress</code>: Total height gained</li> <li><code>avg_movement_economy</code>: Average efficiency ratio</li> </ul>"},{"location":"metrics/#technique-counts","title":"Technique Counts","text":"<ul> <li><code>lock_off_count</code>: Number of lock-off moments detected</li> <li><code>lock_off_percentage</code>: Percentage of frames in lock-off</li> <li><code>rest_count</code>: Number of rest positions</li> <li><code>rest_percentage</code>: Percentage of frames resting</li> </ul>"},{"location":"metrics/#fatigue-indicator","title":"Fatigue Indicator","text":"<ul> <li><code>fatigue_score</code>: Movement quality degradation score</li> <li>0.0 = No degradation</li> <li>0.5 = Moderate fatigue</li> <li> <p>1.0 = Significant fatigue</p> </li> </ul>"},{"location":"metrics/#joint-angle-averages","title":"Joint Angle Averages","text":"<ul> <li><code>avg_joint_angles</code>: Dictionary of average angles for all 8 joints</li> </ul>"},{"location":"metrics/#time-series-history","title":"Time-Series History","text":"<p>Available via <code>analyzer.get_history()</code>:</p> <p>Returns a dictionary with complete frame-by-frame history:</p> <pre><code>{\n    'hip_heights': [0.8, 0.79, 0.78, ...],\n    'velocities': [0.05, 0.06, 0.04, ...],\n    'sways': [0.01, 0.015, 0.012, ...],\n    'jerks': [0.0005, 0.0008, 0.0004, ...],\n    'body_angles': [15.2, 18.5, 12.3, ...],\n    'hand_spans': [0.35, 0.38, 0.42, ...],\n    'foot_spans': [0.28, 0.30, 0.29, ...],\n    'movement_economy': [0.85, 0.82, 0.88, ...],\n    'lock_offs': [False, False, True, ...],\n    'rest_positions': [False, True, True, ...],\n    'joint_angles': {\n        'left_elbow': [145, 148, 142, ...],\n        'right_elbow': [150, 152, 149, ...],\n        # ... all 8 joints\n    }\n}\n</code></pre>"},{"location":"metrics/#usage-examples","title":"Usage Examples","text":""},{"location":"metrics/#analyzing-real-time-performance","title":"Analyzing Real-Time Performance","text":"<pre><code>metrics = analyzer.analyze_frame(landmarks)\n\n# Check if climber is efficient\nif metrics['movement_economy'] &gt; 0.8:\n    print(\"Excellent technique!\")\n\n# Detect fatigue\nif metrics['jerk'] &gt; 0.005:\n    print(\"Movement becoming jerky - possible fatigue\")\n\n# Monitor stability\nif metrics['com_sway'] &gt; 0.03:\n    print(\"Unstable - focus on control\")\n</code></pre>"},{"location":"metrics/#comparing-climb-attempts","title":"Comparing Climb Attempts","text":"<pre><code># After each climb\nsummary = analyzer.get_summary()\n\nclimbs = []\nclimbs.append({\n    'avg_velocity': summary['avg_velocity'],\n    'movement_economy': summary['avg_movement_economy'],\n    'lock_off_percentage': summary['lock_off_percentage']\n})\n\n# Compare best attempt\nbest = max(climbs, key=lambda x: x['movement_economy'])\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#cli-usage","title":"CLI Usage","text":"<p>The fastest way to analyze a climbing video is using the command-line interface:</p>"},{"location":"quickstart/#basic-analysis","title":"Basic Analysis","text":"<pre><code># Quick terminal summary (fast)\npython scripts/analyze_climb.py climbing_video.mp4\n</code></pre> <p>This outputs climbing metrics directly to the terminal.</p>"},{"location":"quickstart/#export-data","title":"Export Data","text":"<pre><code># Export detailed JSON data\npython scripts/analyze_climb.py climbing_video.mp4 --json analysis.json\n</code></pre> <p>The JSON file contains all frame-by-frame metrics and summary statistics.</p>"},{"location":"quickstart/#create-annotated-video","title":"Create Annotated Video","text":"<pre><code># Create video with metrics dashboard on the side (default: no overlay)\npython scripts/analyze_climb.py climbing_video.mp4 --video output.mp4\n\n# Customize dashboard position (left or right)\npython scripts/analyze_climb.py climbing_video.mp4 --video output.mp4 --position left\n\n# Use overlay mode instead of side-by-side\npython scripts/analyze_climb.py climbing_video.mp4 --video output.mp4 --overlay\n\n# Add text overlay with current metric values\npython scripts/analyze_climb.py climbing_video.mp4 --video output.mp4 --show-text\n</code></pre>"},{"location":"quickstart/#combined-export","title":"Combined Export","text":"<pre><code># Export both JSON and video in one pass\npython scripts/analyze_climb.py climbing_video.mp4 --json data.json --video output.mp4\n</code></pre>"},{"location":"quickstart/#python-api","title":"Python API","text":""},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":"<pre><code>from climb_sensei import PoseEngine, VideoReader, ClimbingAnalyzer\n\n# Initialize analyzer\nanalyzer = ClimbingAnalyzer(window_size=30, fps=30)\n\nwith PoseEngine() as engine:\n    with VideoReader('climbing_video.mp4') as video:\n        while True:\n            success, frame = video.read()\n            if not success:\n                break\n\n            # Detect pose\n            results = engine.process(frame)\n            if results:\n                # Extract landmarks\n                landmarks = engine.extract_landmarks(results)\n\n                # Analyze frame - get all metrics\n                metrics = analyzer.analyze_frame(landmarks)\n                print(f\"Velocity: {metrics['com_velocity']:.4f}\")\n                print(f\"Stability: {metrics['com_sway']:.4f}\")\n                print(f\"Progress: {metrics['vertical_progress']:.3f}\")\n\n# Get summary statistics\nsummary = analyzer.get_summary()\nprint(f\"Average speed: {summary['avg_velocity']:.4f}\")\nprint(f\"Total vertical progress: {summary['total_vertical_progress']:.3f}\")\n</code></pre>"},{"location":"quickstart/#running-the-demo","title":"Running the Demo","text":"<pre><code># Run the interactive demo\nuv run python -m climb_sensei\n</code></pre> <p>The demo will:</p> <ol> <li>Open your webcam</li> <li>Detect your pose in real-time</li> <li>Display pose landmarks and basic metrics</li> <li>Press 'q' to quit</li> </ol>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Usage Guide for detailed examples</li> <li>Check the Metrics Reference to understand all available metrics</li> <li>Explore the API Reference for complete documentation</li> </ul>"},{"location":"usage/","title":"Usage Guide","text":""},{"location":"usage/#analyzing-climbing-performance","title":"Analyzing Climbing Performance","text":""},{"location":"usage/#climbinganalyzer","title":"ClimbingAnalyzer","text":"<p>The <code>ClimbingAnalyzer</code> class is the main interface for analyzing climbing metrics:</p> <pre><code>from climb_sensei import ClimbingAnalyzer\n\n# Initialize with custom parameters\nanalyzer = ClimbingAnalyzer(\n    window_size=30,  # Frames for moving average (1 second at 30fps)\n    fps=30           # Video frame rate\n)\n\n# Analyze each frame\nmetrics = analyzer.analyze_frame(landmarks)\n</code></pre>"},{"location":"usage/#available-metrics","title":"Available Metrics","text":"<p>Each call to <code>analyze_frame()</code> returns a dictionary with:</p>"},{"location":"usage/#core-movement-metrics","title":"Core Movement Metrics","text":"<ul> <li><code>hip_height</code>: Current hip position (vertical coordinate)</li> <li><code>com_velocity</code>: Movement speed (units/second)</li> <li><code>com_sway</code>: Lateral stability (lower = more stable)</li> <li><code>jerk</code>: Movement smoothness (lower = smoother)</li> <li><code>body_angle</code>: Lean from vertical (0\u00b0 = vertical, 90\u00b0 = horizontal)</li> <li><code>hand_span</code>: Distance between hands</li> <li><code>foot_span</code>: Distance between feet</li> <li><code>vertical_progress</code>: Height gained from start</li> </ul>"},{"location":"usage/#efficiency-technique","title":"Efficiency &amp; Technique","text":"<ul> <li><code>movement_economy</code>: Vertical progress / total distance (higher = more efficient)</li> <li><code>is_lock_off</code>: Static bent-arm position detected (boolean)</li> <li><code>left_lock_off</code>: Left arm lock-off detection (boolean)</li> <li><code>right_lock_off</code>: Right arm lock-off detection (boolean)</li> <li><code>is_rest_position</code>: Low-stress vertical position detected (boolean)</li> </ul>"},{"location":"usage/#joint-angles-8-joints","title":"Joint Angles (8 joints)","text":"<ul> <li><code>left_elbow</code>, <code>right_elbow</code>: Elbow flexion angles</li> <li><code>left_shoulder</code>, <code>right_shoulder</code>: Shoulder angles</li> <li><code>left_knee</code>, <code>right_knee</code>: Knee flexion angles</li> <li><code>left_hip</code>, <code>right_hip</code>: Hip angles</li> </ul>"},{"location":"usage/#getting-historical-data","title":"Getting Historical Data","text":"<pre><code># Get complete time-series history\nhistory = analyzer.get_history()\n\n# Access specific metric histories\nvelocities = history['velocities']\nsways = history['sways']\nbody_angles = history['body_angles']\njoint_angles = history['joint_angles']  # Dict of all 8 joints\n</code></pre>"},{"location":"usage/#summary-statistics","title":"Summary Statistics","text":"<pre><code># Get summary with all aggregated metrics\nsummary = analyzer.get_summary()\n\n# Available summary stats:\n# - avg_velocity: Average movement speed\n# - total_vertical_progress: Total height gained\n# - avg_movement_economy: Average efficiency\n# - lock_off_count: Number of lock-off moments\n# - lock_off_percentage: Percentage of time in lock-off\n# - rest_count: Number of rest positions\n# - rest_percentage: Percentage of time resting\n# - fatigue_score: Quality degradation indicator\n# - avg_joint_angles: Average angle for each joint\n</code></pre>"},{"location":"usage/#video-processing","title":"Video Processing","text":""},{"location":"usage/#reading-videos","title":"Reading Videos","text":"<pre><code>from climb_sensei import VideoReader\n\nwith VideoReader('input.mp4') as video:\n    # Get video properties\n    print(f\"FPS: {video.fps}\")\n    print(f\"Size: {video.width}x{video.height}\")\n    print(f\"Total frames: {video.frame_count}\")\n\n    # Read frames\n    while True:\n        success, frame = video.read()\n        if not success:\n            break\n        # Process frame...\n</code></pre>"},{"location":"usage/#writing-videos","title":"Writing Videos","text":"<pre><code>from climb_sensei import VideoWriter\n\nwith VideoWriter('output.mp4', fps=30, width=1920, height=1080) as writer:\n    for frame in frames:\n        writer.write(frame)\n</code></pre>"},{"location":"usage/#pose-detection","title":"Pose Detection","text":""},{"location":"usage/#poseengine","title":"PoseEngine","text":"<pre><code>from climb_sensei import PoseEngine\n\n# Initialize with custom confidence thresholds\nengine = PoseEngine(\n    min_detection_confidence=0.5,\n    min_tracking_confidence=0.5\n)\n\n# Process frames\nresults = engine.process(frame)\n\n# Extract landmarks (33 pose landmarks)\nif results:\n    landmarks = engine.extract_landmarks(results)\n    # landmarks is a list of (x, y) tuples\n\n# Close when done (or use context manager)\nengine.close()\n</code></pre>"},{"location":"usage/#context-manager","title":"Context Manager","text":"<pre><code>with PoseEngine() as engine:\n    results = engine.process(frame)\n    # Engine automatically closes\n</code></pre>"},{"location":"usage/#visualization","title":"Visualization","text":""},{"location":"usage/#drawing-pose-landmarks","title":"Drawing Pose Landmarks","text":"<pre><code>from climb_sensei.viz import draw_pose_landmarks\n\n# Draw pose on frame\nannotated_frame = draw_pose_landmarks(frame, landmarks)\n</code></pre>"},{"location":"usage/#creating-dashboards","title":"Creating Dashboards","text":"<pre><code>from climb_sensei.metrics_viz import (\n    create_metrics_dashboard,\n    compose_frame_with_dashboard\n)\n\n# Create dashboard with plots\ndashboard = create_metrics_dashboard(history, width=800, height=1920)\n\n# Compose side-by-side (default)\noutput = compose_frame_with_dashboard(frame, dashboard, position='right')\n\n# Or use overlay mode\nfrom climb_sensei.metrics_viz import overlay_metrics_on_frame\noutput = overlay_metrics_on_frame(frame, dashboard, alpha=0.7)\n</code></pre>"},{"location":"usage/#biomechanics-functions","title":"Biomechanics Functions","text":"<p>Low-level mathematical functions for custom calculations:</p> <pre><code>from climb_sensei.biomechanics import (\n    calculate_joint_angle,\n    calculate_reach_distance,\n    calculate_center_of_mass,\n    calculate_limb_angles,\n    calculate_total_distance_traveled\n)\n\n# Joint angle at point B formed by A-B-C\nangle = calculate_joint_angle(point_a, point_b, point_c)\n\n# Euclidean distance\ndistance = calculate_reach_distance(point_a, point_b)\n\n# Weighted center of mass\ncenter = calculate_center_of_mass(points, weights)\n\n# Calculate all 8 joint angles at once\nangles = calculate_limb_angles(landmarks)\n# Returns dict: {\n#   'left_elbow': 145.2,\n#   'right_elbow': 148.3,\n#   'left_shoulder': 92.1,\n#   ...\n# }\n\n# Total distance traveled\ndistance = calculate_total_distance_traveled(com_positions)\n</code></pre>"},{"location":"usage/#complete-pipeline-example","title":"Complete Pipeline Example","text":"<pre><code>from climb_sensei import (\n    PoseEngine, VideoReader, VideoWriter,\n    ClimbingAnalyzer, draw_pose_landmarks\n)\nfrom climb_sensei.metrics_viz import compose_frame_with_dashboard\n\n# Initialize\nanalyzer = ClimbingAnalyzer(window_size=30, fps=30)\n\nwith PoseEngine() as engine:\n    with VideoReader('input.mp4') as reader:\n        with VideoWriter('output.mp4', fps=reader.fps,\n                        width=reader.width + 800,\n                        height=reader.height) as writer:\n\n            while True:\n                success, frame = reader.read()\n                if not success:\n                    break\n\n                # Detect and analyze\n                results = engine.process(frame)\n                if results:\n                    landmarks = engine.extract_landmarks(results)\n                    metrics = analyzer.analyze_frame(landmarks)\n\n                    # Visualize\n                    annotated = draw_pose_landmarks(frame, landmarks)\n                    history = analyzer.get_history()\n                    dashboard = create_metrics_dashboard(history, 800, frame.shape[0])\n                    output = compose_frame_with_dashboard(annotated, dashboard)\n\n                    writer.write(output)\n\n# Export data\nimport json\nsummary = analyzer.get_summary()\nwith open('analysis.json', 'w') as f:\n    json.dump(summary, f, indent=2)\n</code></pre>"}]}